---
title: "Patient Segmentation"
author: "Jeremy Binagia and Sai Gourisankar"
date: "7/5/2019"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Notes/Assumptions
- As stated [here](https://datascience.stackexchange.com/questions/22/k-means-clustering-for-mixed-numeric-and-categorical-data?answertab=votes#tab-top), k-means clustering can not be immediately used with categorical data. For this reason, we will focus on the quantitative data for the purpose of segmentation.
- We also do not want to categorize based on IDs since these are arbitrarily assigned and are not measuring some intrinsic property; thus, we exclude these columns as well.
- Segmentation is only based on variables measured on the initial day.
- Finally, including `PANSS_Total` is redundant so our relavent columns are just the 30 assessments.


## Setup
```{r Load Libraries, results='hide'}
#library(dplyr)
library(ggplot2)
library(hexbin)
library(RColorBrewer)
library(ggrepel)
library(ggfortify)
library(extrafont)
library(factoextra)
```

```{r Load Data}
A_df=read.csv("Data/Study_A.csv")
B_df=read.csv("Data/Study_B.csv")
C_df=read.csv("Data/Study_C.csv")
D_df=read.csv("Data/Study_D.csv")
E_df=read.csv("Data/Study_E.csv")
summary(A_df)
```

## Clean and organize the data before unsupervised learning

### Only examine the first day
```{r first day}
A_df = subset(A_df, VisitDay==0)
B_df = subset(B_df, VisitDay==0)
C_df = subset(C_df, VisitDay==0)
D_df = subset(D_df, VisitDay==0)
E_df = subset(E_df, VisitDay==0)
```

```{r remove columns}
A_sub = A_df[ , -which(names(A_df) %in% c("Study","Country","PatientID","SiteID","RaterID","AssessmentiD","TxGroup","VisitDay","PANSS_Total","LeadStatus"))]
B_sub = B_df[ , -which(names(B_df) %in% c("Study","Country","PatientID","SiteID","RaterID","AssessmentiD","TxGroup","VisitDay","PANSS_Total","LeadStatus"))]
C_sub = C_df[ , -which(names(C_df) %in% c("Study","Country","PatientID","SiteID","RaterID","AssessmentiD","TxGroup","VisitDay","PANSS_Total","LeadStatus"))]
D_sub = D_df[ , -which(names(D_df) %in% c("Study","Country","PatientID","SiteID","RaterID","AssessmentiD","TxGroup","VisitDay","PANSS_Total","LeadStatus"))]
E_sub = E_df[ , -which(names(E_df) %in% c("Study","Country","PatientID","SiteID","RaterID","AssessmentiD","TxGroup","VisitDay","PANSS_Total","LeadStatus"))]
names(A_sub)
```

### Merge dataframes
```{r merge}
combined_df = rbind(A_sub,B_sub,C_sub,D_sub,E_sub)
```

### Scale
```{r scale}
A_scale = scale(A_sub)
B_scale = scale(B_sub)
C_scale = scale(C_sub)
D_scale = scale(D_sub)
E_scale = scale(E_sub)
scaled_df = scale(combined_df)
summary(scaled_df)
```

## determine optimal number of clusters
```{r optimal-k}
# Elbow method
fviz_nbclust(scaled_df, kmeans, method = "wss") +
    geom_vline(xintercept = 4, linetype = 2)+
  labs(subtitle = "Elbow method")

# Silhouette method
fviz_nbclust(scaled_df, kmeans, method = "silhouette")+
  labs(subtitle = "Silhouette method")

# Gap statistic
# nboot = 50 to keep the function speedy.
# recommended value: nboot= 500 for your analysis.
# Use verbose = FALSE to hide computing progression.

#set.seed(1)
#fviz_nbclust(scaled_df, kmeans, nstart = 25,  method = "gap_stat", nboot = 50)+
#  labs(subtitle = "Gap statistic method")
```

## K-means clustering
```{r k-means}
set.seed(1)
km.out = kmeans(scaled_df, 2, nstart =50)
km.clusters =km.out$cluster
km.out$tot.withinss # total within-cluster sum of squares
km.out$withinss # within-cluster sum of squares

## k-means information
```{r k-means-info}
km.out$size # cluster size
#km.out$centers # cluster means
```

## visualize results
```{r k-means-visual}
fviz_cluster(km.out, scaled_df,geom = c("point"))
```

## pam clustering
```{r pam}
#require(cluster)
pam.res <- pam(scaled_df, 2)
 # Visualize pam clustering
fviz_cluster(pam.res, geom = "point", ellipse.type = "norm")
```


## Hierarchical Clustering
```{r remove columns}
#keep country this time
A_sub = A_df[ , -which(names(A_df) %in% c("Study","PatientID","SiteID","RaterID","AssessmentiD","TxGroup","VisitDay","PANSS_Total","LeadStatus"))]
B_sub = B_df[ , -which(names(B_df) %in% c("Study","PatientID","SiteID","RaterID","AssessmentiD","TxGroup","VisitDay","PANSS_Total","LeadStatus"))]
C_sub = C_df[ , -which(names(C_df) %in% c("Study","PatientID","SiteID","RaterID","AssessmentiD","TxGroup","VisitDay","PANSS_Total","LeadStatus"))]
D_sub = D_df[ , -which(names(D_df) %in% c("Study","PatientID","SiteID","RaterID","AssessmentiD","TxGroup","VisitDay","PANSS_Total","LeadStatus"))]
E_sub = E_df[ , -which(names(E_df) %in% c("Study","PatientID","SiteID","RaterID","AssessmentiD","TxGroup","VisitDay","PANSS_Total","LeadStatus"))]
names(A_sub)
```

### Merge dataframes
```{r merge}
combined_df = rbind(A_sub,B_sub,C_sub,D_sub,E_sub)
```

### Scale
```{r scale}
combined.data=combined_df[,2:31]
combined.labs=combined_df[,1]
scaled_data = scale(combined.data)
summary(scaled_data)
summary(combined.labs)
```

```{r hclust}
library("factoextra")
hc.complete=hclust (dist(combined.data),method="complete")
par(mfrow =c(1,1))
plot(hc.complete,labels=combined.labs,main="Complete Linkage",xlab="",sub="",ylab="")
fviz_dend(hc.complete,labels=combined.labs)
```
