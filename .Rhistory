names(combined.dev.h2o)
combined.dev.h2o=combined.dev.h2o %>%
mutate_if(is.factor,factor,ordered=FALSE) %>%
as.h2o()
performance.train=h2o.performance(train.nb,xval=TRUE)
performance.dev=h2o.performance(train.nb,newdata=combined.dev.h2o)
logloss.train = h2o.logloss(performance.train,xval=TRUE)
logloss.dev=h2o.logloss(performance.dev,xval=TRUE)
auc.train <- h2o.auc(performance.train,xval=TRUE)
auc.dev <- h2o.auc(performance.dev)
fpr.dev <- h2o.fpr(performance.dev) %>% .[['fpr']]
tpr.dev <- h2o.tpr(performance.dev) %>% .[['tpr']]
data.frame(fpr = fpr.dev, tpr = tpr.dev) %>%
ggplot(aes(fpr, tpr) ) +
geom_line() +
ggtitle( sprintf('Development Dataset AUC, LogLoss: %f, %f', auc.dev,logloss.dev) )
# predict values with predict -->
names(test)
test.h2o=test[,-3]#get rid of VisitDay
#test.h2o=test.h2o[,-4]#get rid of AssessmentiD
test.h2o=test.h2o %>%
mutate_if(is.factor,factor,ordered=FALSE)%>%
as.h2o()
str(test.h2o)
nb.predictions=h2o.predict(train.nb,test.h2o)
nb.predictions_df=as.data.frame(nb.predictions)
test$LeadStatus=nb.predictions_df$Flagged
test.output=test[,c("AssessmentiD","LeadStatus")]
write.csv(test.output,"test.nb.csv",row.names=FALSE)
library(pROC)
names(combined.train)
combined.train.glm=combined.train[,-1] # exclude country from being a predictor
attach(combined.train.glm)
names(combined.train.glm)
train.glm=glm(LeadStatus~.,data=combined.train.glm,family=binomial)
summary(train.glm)
contrasts(LeadStatus)#check dummy encoding for Up/Down
#dev test
glm.probs.flag.dev=1-predict(train.glm,combined.dev,type="response")
glm.pred=rep("Passed",dim(combined.dev)[1])#create vector of predictions of length the same as dev dataset
glm.pred[glm.probs.flag.dev>0.2]="Flagged"#change relevant values to "Flagged" based on model-predicted value.
table(glm.pred,combined.dev$LeadStatus)
roc.dev=roc(LeadStatus~glm.probs.flag.dev,data=combined.dev)
plot(roc.dev,xlim=c(0,1),ylim=c(0,1))
#kaggle test
test=E_df
glm.probs=predict(train.glm,test,type="response")#compute predictions based on fit for each observation; 1 corresponds to Passed
glm.probs.flag=1-glm.probs#probabililty of being flagged for all.
names(test)
test.output.glm=as.data.frame(test$AssessmentiD)
test.output.glm$LeadStatus=glm.probs.flag
colnames(test.output.glm)[colnames(test.output.glm)=="AssessmentiD"] <- "AssessmentID"
write.csv(test.output.glm,"Predictions/test.glm.csv",row.names=FALSE)
plot(test.output.glm$LeadStatus,nb.predictions_df$Flagged,xlim=c(0,0.5),ylim=c(0,0.5))
abline(0,1)
full.glm=glm(LeadStatus~.,data=combined_df[,-1],family=binomial)
summary(full.glm)
contrasts(LeadStatus)#check dummy encoding for Up/Down
test=E_df
glm.probs=predict(full.glm,test,type="response")#compute predictions based on fit for each observation; 1 corresponds to Passed
glm.probs.flag=1-glm.probs#probabililty of being flagged for all.
test.full.glm=as.data.frame(test$AssessmentiD)
test.full.glm$LeadStatus=glm.probs.flag
colnames(test.full.glm)[colnames(test.full.glm)=="AssessmentiD"] <- "AssessmentID"
write.csv(test.full.glm,"Predictions/test.glm.full.csv",row.names=FALSE)
plot(test.full.glm$LeadStatus,test.output.glm$LeadStatus)
abline(0,1)
combined.all = rbind(A_init_df, B_init_df, C_init_df, D_init_df)
combined.all = subset(combined.all,select = setdiff(names(combined.all),c("Country","Study","PatientID","RaterID","AssessmentiD","PANSS_Total","SiteID")))
names(combined.all)
combined.all = distinct(combined.all)
combined.all <- mutate_at(combined.all, vars(TxGroup,LeadStatus), as.factor)
# str(combined.all) # compactly display structure of the object
E_df<-mutate_at(E_df,vars(Country, TxGroup,AssessmentiD),as.factor)
# str(E_df)
combined.all$LeadStatus[combined.all$LeadStatus!="Passed"]<-"Flagged"
combined.all$LeadStatus = factor(combined.all$LeadStatus)
table(combined.all$LeadStatus) # how many passed vs. not
set.seed(1)
tot = 1:dim(combined.all)[1] # total number of observations
train = sample(tot,length(tot)*0.7) # put 70% of observations into training set
combined.train.all = combined.all[train,]
head(combined.train.all) # visually check data frame
dev = tot[-train] # rest go into development set
combined.dev.all = combined.all[dev,]
test.all = E_df # study E is the test set
model1 <- glm(LeadStatus ~., family = "binomial", data = combined.train.all)
summary(model1)
?tidy
library(broom)      # helps to tidy up model outputs
tidy(model1)
caret::varImp(model3)
library(broom)      # helps to tidy up model outputs
tidy(model1)
caret::varImp(model1)
varimp.plot(model1)
varImp.plot(model1)
varImp.plot.train(model1)
library(broom)      # helps to tidy up model outputs
tidy(model1)
plot(caret::varImp(model1))
library(broom)      # helps to tidy up model outputs
tidy(model1)
caret::varImp(model1)
varImpPlot(model1,type=2)
library(broom)      # helps to tidy up model outputs
tidy(model1)
caret::varImp(model1)
caret:varImpPlot(model1,type=2)
library(broom)      # helps to tidy up model outputs
tidy(model1)
caret::varImp(model1)
caret::varImpPlot(model1,type=2)
library(broom)      # helps to tidy up model outputs
tidy(model1)
caret::varImp(model1)
caret::varImpPlot(model1,type=2)
library(broom)      # helps to tidy up model outputs
tidy(model1)
sort(caret::varImp(model1))
caret::varImp(model1)
?sort
library(broom)      # helps to tidy up model outputs
tidy(model1)
caret::varImp(model1)
dev.log.all.pred = predict(model1, newdata = combined.dev.all)
table(combined.dev.all$LeadStatus, dev.log.all.pred$class) %>% prop.table() %>% round(3)
summary(dev.log.all.pred)
dev.log.all.pred
str(dev.log.all.pred)
dev.log.all.pred = predict(model1, newdata = combined.dev.all, type="response")
table(combined.dev.all$LeadStatus, dev.log.all.pred$class) %>% prop.table() %>% round(3)
dev.log.all.pred
str(dev.log.all.pred)
dev.log.all.pred = predict(model1, newdata = combined.dev.all, type="response")
table(combined.dev.all$LeadStatus, dev.log.all.pred) %>% prop.table() %>% round(3)
# accuracy rate
mean(dev.log.all.preds == combined.dev.all$LeadStatus)
dev.log.all.pred = predict(model1, newdata = combined.dev.all, type="response")
table(combined.dev.all$LeadStatus, dev.log.all.pred) %>% prop.table() %>% round(3)
# accuracy rate
mean(dev.log.all.pred == combined.dev.all$LeadStatus)
# error rate
mean(dev.log.all.pred != combined.dev.all$LeadStatus)
install.packages(c("clValid", "factoextra", "FactoMineR", "NbClust"))
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(hexbin)
library(RColorBrewer)
library(ggrepel)
library(ggfortify)
library(extrafont)
library(factoextra)
library("FactoMineR")
library(NbClust)
library(cluster)
library(clValid)
library(ggfortify)
A_df=read.csv("Data/Study_A.csv")
B_df=read.csv("Data/Study_B.csv")
C_df=read.csv("Data/Study_C.csv")
D_df=read.csv("Data/Study_D.csv")
E_df=read.csv("Data/Study_E.csv")
summary(A_df)
A_df = subset(A_df, VisitDay==0)
B_df = subset(B_df, VisitDay==0)
C_df = subset(C_df, VisitDay==0)
D_df = subset(D_df, VisitDay==0)
E_df = subset(E_df, VisitDay==0)
A_sub = A_df[ , -which(names(A_df) %in% c("Study","Country","PatientID","SiteID","RaterID",
"AssessmentiD","TxGroup","VisitDay","PANSS_Total","LeadStatus"))]
B_sub = B_df[ , -which(names(B_df) %in% c("Study","Country","PatientID","SiteID","RaterID",
"AssessmentiD","TxGroup","VisitDay","PANSS_Total","LeadStatus"))]
C_sub = C_df[ , -which(names(C_df) %in% c("Study","Country","PatientID","SiteID","RaterID",
"AssessmentiD","TxGroup","VisitDay","PANSS_Total","LeadStatus"))]
D_sub = D_df[ , -which(names(D_df) %in% c("Study","Country","PatientID","SiteID","RaterID",
"AssessmentiD","TxGroup","VisitDay","PANSS_Total","LeadStatus"))]
E_sub = E_df[ , -which(names(E_df) %in% c("Study","Country","PatientID","SiteID","RaterID",
"AssessmentiD","TxGroup","VisitDay","PANSS_Total","LeadStatus"))]
names(A_sub)
combined_df = rbind(A_sub,B_sub,C_sub,D_sub,E_sub)
A_scale = scale(A_sub)
B_scale = scale(B_sub)
C_scale = scale(C_sub)
D_scale = scale(D_sub)
E_scale = scale(E_sub)
scaled_df = scale(combined_df)
summary(scaled_df)
#cvalid.out = clValid(scaled_df, maxitems = 3000, nClust = 2:8,
#                     clMethods = c("kmeans","pam"), validation = c("internal", "stability"))
#summary(cvalid.out)
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(hexbin)
library(RColorBrewer)
library(ggrepel)
library(ggfortify)
library(extrafont)
library(factoextra)
library("FactoMineR")
library(NbClust)
library(cluster)
library(clValid)
library(ggfortify)
A_df=read.csv("Data/Study_A.csv")
B_df=read.csv("Data/Study_B.csv")
C_df=read.csv("Data/Study_C.csv")
D_df=read.csv("Data/Study_D.csv")
E_df=read.csv("Data/Study_E.csv")
summary(A_df)
A_df = subset(A_df, VisitDay==0)
B_df = subset(B_df, VisitDay==0)
C_df = subset(C_df, VisitDay==0)
D_df = subset(D_df, VisitDay==0)
E_df = subset(E_df, VisitDay==0)
A_sub = A_df[ , -which(names(A_df) %in% c("Study","Country","PatientID","SiteID","RaterID",
"AssessmentiD","TxGroup","VisitDay","PANSS_Total","LeadStatus"))]
B_sub = B_df[ , -which(names(B_df) %in% c("Study","Country","PatientID","SiteID","RaterID",
"AssessmentiD","TxGroup","VisitDay","PANSS_Total","LeadStatus"))]
C_sub = C_df[ , -which(names(C_df) %in% c("Study","Country","PatientID","SiteID","RaterID",
"AssessmentiD","TxGroup","VisitDay","PANSS_Total","LeadStatus"))]
D_sub = D_df[ , -which(names(D_df) %in% c("Study","Country","PatientID","SiteID","RaterID",
"AssessmentiD","TxGroup","VisitDay","PANSS_Total","LeadStatus"))]
E_sub = E_df[ , -which(names(E_df) %in% c("Study","Country","PatientID","SiteID","RaterID",
"AssessmentiD","TxGroup","VisitDay","PANSS_Total","LeadStatus"))]
names(A_sub)
combined_df = rbind(A_sub,B_sub,C_sub,D_sub,E_sub)
A_scale = scale(A_sub)
B_scale = scale(B_sub)
C_scale = scale(C_sub)
D_scale = scale(D_sub)
E_scale = scale(E_sub)
scaled_df = scale(combined_df)
summary(scaled_df)
#cvalid.out = clValid(scaled_df, maxitems = 3000, nClust = 2:8,
#                     clMethods = c("kmeans","pam"), validation = c("internal", "stability"))
#summary(cvalid.out)
# Elbow method
fviz_nbclust(scaled_df, kmeans, method = "wss",print.summary=TRUE) +
geom_vline(xintercept = 2, linetype = 2)+
labs(subtitle = "Elbow method")
# Silhouette method
fviz_nbclust(scaled_df, kmeans, method = "silhouette")+
labs(subtitle = "Silhouette method")
# Gap statistic
# nboot = 50 to keep the function speedy. Number of Monte Carlo ("bootstrap") samples.
# recommended value: nboot= 500 for your analysis.
# Use verbose = FALSE to hide computing progression.
# set.seed(1)
# gc()
# fviz_nbclust(scaled_df, kmeans,k.max = 10,iter.max=30,nstart = 25,method="gap_stat",nboot = 500)+
#   labs(subtitle = "Gap statistic method")
NbClust(data = scaled_df, distance = "euclidean", min.nc = 2, max.nc = 10, method = "kmeans");
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(hexbin)
library(RColorBrewer)
library(ggrepel)
library(ggfortify)
library(extrafont)
library(factoextra)
library("FactoMineR")
library(NbClust)
library(cluster)
library(clValid)
library(ggfortify)
A_df=read.csv("Data/Study_A.csv")
B_df=read.csv("Data/Study_B.csv")
C_df=read.csv("Data/Study_C.csv")
D_df=read.csv("Data/Study_D.csv")
E_df=read.csv("Data/Study_E.csv")
summary(A_df)
A_df = subset(A_df, VisitDay==0)
B_df = subset(B_df, VisitDay==0)
C_df = subset(C_df, VisitDay==0)
D_df = subset(D_df, VisitDay==0)
E_df = subset(E_df, VisitDay==0)
A_sub = A_df[ , -which(names(A_df) %in% c("Study","Country","PatientID","SiteID","RaterID",
"AssessmentiD","TxGroup","VisitDay","PANSS_Total","LeadStatus"))]
B_sub = B_df[ , -which(names(B_df) %in% c("Study","Country","PatientID","SiteID","RaterID",
"AssessmentiD","TxGroup","VisitDay","PANSS_Total","LeadStatus"))]
C_sub = C_df[ , -which(names(C_df) %in% c("Study","Country","PatientID","SiteID","RaterID",
"AssessmentiD","TxGroup","VisitDay","PANSS_Total","LeadStatus"))]
D_sub = D_df[ , -which(names(D_df) %in% c("Study","Country","PatientID","SiteID","RaterID",
"AssessmentiD","TxGroup","VisitDay","PANSS_Total","LeadStatus"))]
E_sub = E_df[ , -which(names(E_df) %in% c("Study","Country","PatientID","SiteID","RaterID",
"AssessmentiD","TxGroup","VisitDay","PANSS_Total","LeadStatus"))]
names(A_sub)
combined_df = rbind(A_sub,B_sub,C_sub,D_sub,E_sub)
A_scale = scale(A_sub)
B_scale = scale(B_sub)
C_scale = scale(C_sub)
D_scale = scale(D_sub)
E_scale = scale(E_sub)
scaled_df = scale(combined_df)
summary(scaled_df)
#cvalid.out = clValid(scaled_df, maxitems = 3000, nClust = 2:8,
#                     clMethods = c("kmeans","pam"), validation = c("internal", "stability"))
#summary(cvalid.out)
# Elbow method
fviz_nbclust(scaled_df, kmeans, method = "wss",print.summary=TRUE) +
geom_vline(xintercept = 2, linetype = 2)+
labs(subtitle = "Elbow method")
# Silhouette method
fviz_nbclust(scaled_df, kmeans, method = "silhouette")+
labs(subtitle = "Silhouette method")
# Gap statistic
# nboot = 50 to keep the function speedy. Number of Monte Carlo ("bootstrap") samples.
# recommended value: nboot= 500 for your analysis.
# Use verbose = FALSE to hide computing progression.
# set.seed(1)
# gc()
# fviz_nbclust(scaled_df, kmeans,k.max = 10,iter.max=30,nstart = 25,method="gap_stat",nboot = 500)+
#   labs(subtitle = "Gap statistic method")
# NbClust(data = scaled_df, distance = "euclidean", min.nc = 2, max.nc = 10, method = "kmeans");
set.seed(1)
chosen_k = 2
km.out = kmeans(scaled_df, chosen_k, nstart = 50)
km.clusters =km.out$cluster
# stats
km.out$tot.withinss # total within-cluster sum of squares
km.out$withinss # within-cluster sum of squares
km.out$size # cluster size
# visualize
fviz_cluster(km.out, scaled_df,geom = c("point"))
# Elbow method
fviz_nbclust(scaled_df, pam, method = "wss",print.summary=TRUE) +
geom_vline(xintercept = 2, linetype = 2)+
labs(subtitle = "Elbow method")
# Silhouette method
fviz_nbclust(scaled_df, pam, method = "silhouette")+
labs(subtitle = "Silhouette method")
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(hexbin)
library(RColorBrewer)
library(ggrepel)
library(ggfortify)
library(extrafont)
library(factoextra)
library("FactoMineR")
library(NbClust)
library(cluster)
library(clValid)
library(ggfortify)
A_df=read.csv("Data/Study_A.csv")
B_df=read.csv("Data/Study_B.csv")
C_df=read.csv("Data/Study_C.csv")
D_df=read.csv("Data/Study_D.csv")
E_df=read.csv("Data/Study_E.csv")
summary(A_df)
A_df = subset(A_df, VisitDay==0)
B_df = subset(B_df, VisitDay==0)
C_df = subset(C_df, VisitDay==0)
D_df = subset(D_df, VisitDay==0)
E_df = subset(E_df, VisitDay==0)
A_sub = A_df[ , -which(names(A_df) %in% c("Study","Country","PatientID","SiteID","RaterID",
"AssessmentiD","TxGroup","VisitDay","PANSS_Total","LeadStatus"))]
B_sub = B_df[ , -which(names(B_df) %in% c("Study","Country","PatientID","SiteID","RaterID",
"AssessmentiD","TxGroup","VisitDay","PANSS_Total","LeadStatus"))]
C_sub = C_df[ , -which(names(C_df) %in% c("Study","Country","PatientID","SiteID","RaterID",
"AssessmentiD","TxGroup","VisitDay","PANSS_Total","LeadStatus"))]
D_sub = D_df[ , -which(names(D_df) %in% c("Study","Country","PatientID","SiteID","RaterID",
"AssessmentiD","TxGroup","VisitDay","PANSS_Total","LeadStatus"))]
E_sub = E_df[ , -which(names(E_df) %in% c("Study","Country","PatientID","SiteID","RaterID",
"AssessmentiD","TxGroup","VisitDay","PANSS_Total","LeadStatus"))]
names(A_sub)
combined_df = rbind(A_sub,B_sub,C_sub,D_sub,E_sub)
A_scale = scale(A_sub)
B_scale = scale(B_sub)
C_scale = scale(C_sub)
D_scale = scale(D_sub)
E_scale = scale(E_sub)
scaled_df = scale(combined_df)
summary(scaled_df)
#cvalid.out = clValid(scaled_df, maxitems = 3000, nClust = 2:8,
#                     clMethods = c("kmeans","pam"), validation = c("internal", "stability"))
#summary(cvalid.out)
# Elbow method
fviz_nbclust(scaled_df, kmeans, method = "wss",print.summary=TRUE) +
geom_vline(xintercept = 2, linetype = 2)+
labs(subtitle = "Elbow method")
# Silhouette method
fviz_nbclust(scaled_df, kmeans, method = "silhouette")+
labs(subtitle = "Silhouette method")
# Gap statistic
# nboot = 50 to keep the function speedy. Number of Monte Carlo ("bootstrap") samples.
# recommended value: nboot= 500 for your analysis.
# Use verbose = FALSE to hide computing progression.
# set.seed(1)
# gc()
# fviz_nbclust(scaled_df, kmeans,k.max = 10,iter.max=30,nstart = 25,method="gap_stat",nboot = 500)+
#   labs(subtitle = "Gap statistic method")
# NbClust(data = scaled_df, distance = "euclidean", min.nc = 2, max.nc = 10, method = "kmeans");
set.seed(1)
chosen_k = 2
km.out = kmeans(scaled_df, chosen_k, nstart = 50)
km.clusters =km.out$cluster
# stats
km.out$tot.withinss # total within-cluster sum of squares
km.out$withinss # within-cluster sum of squares
km.out$size # cluster size
# visualize
fviz_cluster(km.out, scaled_df,geom = c("point"))
# Elbow method
fviz_nbclust(scaled_df, pam, method = "wss",print.summary=TRUE) +
geom_vline(xintercept = 2, linetype = 2)+
labs(subtitle = "Elbow method")
# Silhouette method
fviz_nbclust(scaled_df, pam, method = "silhouette")+
labs(subtitle = "Silhouette method")
# Gap statistic
# nboot = 50 to keep the function speedy. Number of Monte Carlo ("bootstrap") samples.
# recommended value: nboot= 500 for your analysis.
# Use verbose = FALSE to hide computing progression.
#set.seed(1)
#fviz_nbclust(scaled_df, k.max = 10, pam,method="gap_stat",nboot = 50)+
#  labs(subtitle = "Gap statistic method")
pam.res <- pam(scaled_df, chosen_k)
# Visualize pam clustering
fviz_cluster(pam.res, geom = "point")
pca.out = prcomp(scaled_df, scale=TRUE)
ggplot2::autoplot(pca.out, label = FALSE, loadings.label = TRUE)
pcaCharts <- function(x) {
x.var <- x$sdev ^ 2
x.pvar <- x.var/sum(x.var)
print("proportions of variance:")
print(x.pvar)
par(mfrow=c(2,2))
plot(x.pvar,xlab="Principal component",
ylab="Proportion of variance explained", ylim=c(0,1), type='b')
plot(cumsum(x.pvar),xlab="Principal component",
ylab="Cumulative Proportion of variance explained", ylim=c(0,1), type='b')
screeplot(x)
screeplot(x,type="l")
par(mfrow=c(1,1))
}
# check proportion of variance explained by each component
pcaCharts(pca.out)
pca.out$rotation[,1:3]
res.pca = PCA(scaled_df, graph = FALSE)
print(res.pca)
fviz_screeplot(res.pca, addlabels = TRUE, ylim = c(0, 50))
# Graph of variables: default plot
fviz_pca_var(res.pca, col.var="contrib",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
repel = TRUE # Avoid text overlapping
)
# Contributions of variables to PC1
fviz_contrib(res.pca, choice = "var", axes = 1, top = 10)
# Contributions of variables to PC2
fviz_contrib(res.pca, choice = "var", axes = 2, top = 10)
# Contributions of variables to PC2
fviz_contrib(res.pca, choice = "var", axes = 3, top = 10)
omission_vector = c("Country","PatientID","SiteID","RaterID",
"AssessmentiD","TxGroup","VisitDay","PANSS_Total","LeadStatus")
combined_all_col = rbind(A_df[ , -which(names(A_df) %in% omission_vector)],B_df[ , -which(names(A_df) %in% omission_vector)],C_df[ , -which(names(A_df) %in% omission_vector)],D_df[ , -which(names(A_df) %in% omission_vector)],E_df[ , -which(names(A_df) %in% omission_vector)])
res.pca <- prcomp(combined_all_col[,-1],  scale = TRUE)
fviz(res.pca, "ind", label = "none",habillage=combined_all_col$Study,addEllipses = "True",alpha=0.3,ellipse.type = "convex") # Individuals plot
res.pca <- prcomp(combined_all_col[,-1],  scale = TRUE)
fviz(res.pca, "ind", label = "none",habillage=combined_all_col$Study,addEllipses = "True",alpha=0.3) # Individuals plot
omission_vector = c("Study","PatientID","SiteID","RaterID",
"AssessmentiD","TxGroup","VisitDay","PANSS_Total","LeadStatus")
combined_all_col = rbind(A_df[ , -which(names(A_df) %in% omission_vector)],B_df[ , -which(names(A_df) %in% omission_vector)],C_df[ , -which(names(A_df) %in% omission_vector)],D_df[ , -which(names(A_df) %in% omission_vector)],E_df[ , -which(names(A_df) %in% omission_vector)])
library(plyr)
sort(table(combined_all_col$Country),decreasing=TRUE)
# consider only top 5 countries
countries = c("USA","China","Russia","Japan","Ukraine")
top_5_country_df = subset(combined_all_col, Country %in% countries)
sum(table(top_5_country_df$Country))/sum(table(combined_all_col$Country)) # these countries make up 80%
res.pca <- prcomp(top_5_country_df[,-1],  scale = TRUE)
fviz(res.pca, "ind", label = "none",habillage=top_5_country_df$Country,addEllipses = TRUE,alpha=0.5,ellipse.alpha = 0.25)
#keep country this time
A_sub_hc=A_df[,-which(names(A_df) %in% c("Study","PatientID","SiteID","RaterID","AssessmentiD",
"TxGroup","VisitDay","PANSS_Total","LeadStatus"))]
B_sub_hc=B_df[,-which(names(B_df) %in% c("Study","PatientID","SiteID","RaterID","AssessmentiD",
"TxGroup","VisitDay","PANSS_Total","LeadStatus"))]
C_sub_hc=C_df[,-which(names(C_df) %in% c("Study","PatientID","SiteID","RaterID","AssessmentiD",
"TxGroup","VisitDay","PANSS_Total","LeadStatus"))]
D_sub_hc=D_df[,-which(names(D_df) %in% c("Study","PatientID","SiteID","RaterID","AssessmentiD",
"TxGroup","VisitDay","PANSS_Total","LeadStatus"))]
E_sub_hc=E_df[,-which(names(E_df) %in% c("Study","PatientID","SiteID","RaterID","AssessmentiD",
"TxGroup","VisitDay","PANSS_Total","LeadStatus"))]
names(A_sub)
combined_df_hc = rbind(A_sub_hc,B_sub_hc,C_sub_hc,D_sub_hc,E_sub_hc)
combined.data=combined_df_hc[,2:31]
combined.labs=combined_df_hc[,1]
scaled_data = scale(combined.data)
summary(scaled_data)
summary(combined.labs)
# commented out since was receiving error
#combined_df$Country=combined.labs
#combined_df$Cluster=km.out$cluster
#head(combined_df)
#clust1_df=combined_df[which(combined_df$Cluster==1),]
#clust2_df=combined_df[which(combined_df$Cluster==2),]
#clust3_df=combined_df[which(combined_df$Cluster==3),]
#clust4_df=combined_df[which(combined_df$Cluster==4),]
#par(mfrow=c(2,2))
#hist.c1=barplot(prop.table(table(as.factor(clust1_df$Country))),las=2)
#hist.c2=barplot(prop.table(table(as.factor(clust2_df$Country))),las=2)
#hist.c3=barplot(prop.table(table(as.factor(clust3_df$Country))),las=2)
#hist.c4=barplot(prop.table(table(as.factor(clust4_df$Country))),las=2)
#hc.complete=hclust (dist(combined.data),method="complete")
#par(mfrow =c(1,1))
#plot(hc.complete,labels=combined.labs,main="Complete Linkage",xlab="",sub="",ylab="")
#fviz_dend(hc.complete,labels=combined.labs)
# Compute hierarchical clustering and cut into 4 clusters
#res <- hcut(scaled_df, k = 4, stand = TRUE)
# Visualize
#fviz_dend(res, rect = TRUE, cex = 0.5,
#          k_colors = c("#00AFBB","#2E9FDF", "#E7B800", "#FC4E07"))
