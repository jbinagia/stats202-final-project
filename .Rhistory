#summary(df)
columns(df)
A_scale = scale(A_sub)
B_scale = scale(B_sub)
C_scale = scale(C_sub)
D_scale = scale(D_sub)
E_scale = scale(E_sub)
scaled_df = scale(combined_df)
#summary(scaled_df)
data("USArrests")
df = scale(USArrests)
#summary(df)
names(df)
A_scale = scale(A_sub)
B_scale = scale(B_sub)
C_scale = scale(C_sub)
D_scale = scale(D_sub)
E_scale = scale(E_sub)
scaled_df = scale(combined_df)
#summary(scaled_df)
data("USArrests")
df = scale(USArrests)
#summary(df)
names(USArrests)
A_scale = scale(A_sub)
B_scale = scale(B_sub)
C_scale = scale(C_sub)
D_scale = scale(D_sub)
E_scale = scale(E_sub)
scaled_df = scale(combined_df)
#summary(scaled_df)
data("USArrests")
df = scale(USArrests)
#summary(df)
head(USArrests)
# Elbow method
fviz_nbclust(df, kmeans, method = "wss") +
geom_vline(xintercept = 4, linetype = 2)+
labs(subtitle = "Elbow method")
# Silhouette method
fviz_nbclust(df, kmeans, method = "silhouette")+
labs(subtitle = "Silhouette method")
# Gap statistic
# nboot = 50 to keep the function speedy.
# recommended value: nboot= 500 for your analysis.
# Use verbose = FALSE to hide computing progression.
set.seed(123)
fviz_nbclust(df, kmeans, nstart = 25,  method = "gap_stat", nboot = 50)+
labs(subtitle = "Gap statistic method")
# Elbow method
fviz_nbclust(scaled_df, kmeans, method = "wss") +
geom_vline(xintercept = 4, linetype = 2)+
labs(subtitle = "Elbow method")
# Silhouette method
fviz_nbclust(scaled_df, kmeans, method = "silhouette")+
labs(subtitle = "Silhouette method")
# Gap statistic
# nboot = 50 to keep the function speedy.
# recommended value: nboot= 500 for your analysis.
# Use verbose = FALSE to hide computing progression.
set.seed(1)
fviz_nbclust(scaled_df, kmeans, nstart = 25,  method = "gap_stat", nboot = 50)+
labs(subtitle = "Gap statistic method")
# Elbow method
fviz_nbclust(scaled_df, kmeans, method = "wss") +
geom_vline(xintercept = 4, linetype = 2)+
labs(subtitle = "Elbow method")
# Silhouette method
fviz_nbclust(scaled_df, kmeans, method = "silhouette")+
labs(subtitle = "Silhouette method")
# Gap statistic
# nboot = 50 to keep the function speedy.
# recommended value: nboot= 500 for your analysis.
# Use verbose = FALSE to hide computing progression.
#set.seed(1)
#fviz_nbclust(scaled_df, kmeans, nstart = 25,  method = "gap_stat", nboot = 50)+
#  labs(subtitle = "Gap statistic method")
A_scale = scale(A_sub)
B_scale = scale(B_sub)
C_scale = scale(C_sub)
D_scale = scale(D_sub)
E_scale = scale(E_sub)
scaled_df = scale(combined_df)
#summary(scaled_df)
A_scale = scale(A_sub)
B_scale = scale(B_sub)
C_scale = scale(C_sub)
D_scale = scale(D_sub)
E_scale = scale(E_sub)
scaled_df = scale(combined_df)
summary(scaled_df)
set.seed(1)
km.out = kmeans(scaled_df, 10, nstart =50)
km.clusters =km.out$cluster
km.out$tot.withinss # total within-cluster sum of squares
km.out$withinss # within-cluster sum of squares
km.out$size # cluster size
#km.out$centers # cluster means
fviz_cluster(km.out, scaled_df,geom = c("point"))
#require(cluster)
pam.res <- pam(scaled_df, 3)
# Visualize pam clustering
fviz_cluster(pam.res, geom = "point", ellipse.type = "norm")
#require(cluster)
pam.res <- pam(scaled_df, 10)
# Visualize pam clustering
fviz_cluster(pam.res, geom = "point", ellipse.type = "norm")
#require(cluster)
pam.res <- pam(scaled_df, 2)
# Visualize pam clustering
fviz_cluster(pam.res, geom = "point", ellipse.type = "norm")
fviz_cluster(km.out, scaled_df,geom = c("point"))
set.seed(1)
km.out = kmeans(scaled_df, 2, nstart =50)
km.clusters =km.out$cluster
km.out$tot.withinss # total within-cluster sum of squares
km.out$withinss # within-cluster sum of squares
km.out$size # cluster size
#km.out$centers # cluster means
fviz_cluster(km.out, scaled_df,geom = c("point"))
knitr::opts_chunk$set(echo = TRUE)
# Elbow method
fviz_nbclust(scaled_df, kmeans, method = "wss") +
geom_vline(xintercept = 6, linetype = 2)+
labs(subtitle = "Elbow method")
# Elbow method
fviz_nbclust(scaled_df, kmeans, method = "wss",print.summary=TRUE) +
geom_vline(xintercept = 6, linetype = 2)+
labs(subtitle = "Elbow method")
knitr::opts_chunk$set(echo = TRUE)
#library(dplyr)
library(ggplot2)
library(hexbin)
library(RColorBrewer)
library(ggrepel)
library(ggfortify)
library(extrafont)
library(factoextra)
A_df=read.csv("Data/Study_A.csv")
B_df=read.csv("Data/Study_B.csv")
C_df=read.csv("Data/Study_C.csv")
D_df=read.csv("Data/Study_D.csv")
E_df=read.csv("Data/Study_E.csv")
summary(A_df)
A_df = subset(A_df, VisitDay==0)
B_df = subset(B_df, VisitDay==0)
C_df = subset(C_df, VisitDay==0)
D_df = subset(D_df, VisitDay==0)
E_df = subset(E_df, VisitDay==0)
A_sub = A_df[ , -which(names(A_df) %in% c("Study","Country","PatientID","SiteID","RaterID","AssessmentiD","TxGroup","VisitDay","PANSS_Total","LeadStatus"))]
B_sub = B_df[ , -which(names(B_df) %in% c("Study","Country","PatientID","SiteID","RaterID","AssessmentiD","TxGroup","VisitDay","PANSS_Total","LeadStatus"))]
C_sub = C_df[ , -which(names(C_df) %in% c("Study","Country","PatientID","SiteID","RaterID","AssessmentiD","TxGroup","VisitDay","PANSS_Total","LeadStatus"))]
D_sub = D_df[ , -which(names(D_df) %in% c("Study","Country","PatientID","SiteID","RaterID","AssessmentiD","TxGroup","VisitDay","PANSS_Total","LeadStatus"))]
E_sub = E_df[ , -which(names(E_df) %in% c("Study","Country","PatientID","SiteID","RaterID","AssessmentiD","TxGroup","VisitDay","PANSS_Total","LeadStatus"))]
names(A_sub)
combined_df = rbind(A_sub,B_sub,C_sub,D_sub,E_sub)
A_scale = scale(A_sub)
B_scale = scale(B_sub)
C_scale = scale(C_sub)
D_scale = scale(D_sub)
E_scale = scale(E_sub)
scaled_df = scale(combined_df)
summary(scaled_df)
# Elbow method
fviz_nbclust(scaled_df, kmeans, method = "wss",print.summary=TRUE) +
geom_vline(xintercept = 6, linetype = 2)+
labs(subtitle = "Elbow method")
# Silhouette method
fviz_nbclust(scaled_df, kmeans, method = "silhouette")+
labs(subtitle = "Silhouette method")
# Gap statistic
# nboot = 50 to keep the function speedy.
# recommended value: nboot= 500 for your analysis.
# Use verbose = FALSE to hide computing progression.
#set.seed(1)
#fviz_nbclust(scaled_df, kmeans, nstart = 25,  method = "gap_stat", nboot = 50)+
#  labs(subtitle = "Gap statistic method")
set.seed(1)
km.out = kmeans(scaled_df, 2, nstart =50)
km.clusters =km.out$cluster
km.out$tot.withinss # total within-cluster sum of squares
km.out$withinss # within-cluster sum of squares
km.out$size # cluster size
#km.out$centers # cluster means
fviz_cluster(km.out, scaled_df,geom = c("point"))
#require(cluster)
pam.res <- pam(scaled_df, 2)
# Elbow method
fviz_nbclust(scaled_df, kmeans, method = "wss",print.summary=TRUE) +
geom_vline(xintercept = 6, linetype = 2)+
labs(subtitle = "Elbow method")
# Silhouette method
fviz_nbclust(scaled_df, kmeans, method = "silhouette")+
labs(subtitle = "Silhouette method")
# Gap statistic
# nboot = 50 to keep the function speedy.
# recommended value: nboot= 500 for your analysis.
# Use verbose = FALSE to hide computing progression.
#set.seed(1)
#fviz_nbclust(scaled_df, kmeans, nstart = 25,  method = "gap_stat", nboot = 50)+
#  labs(subtitle = "Gap statistic method")
# Elbow method
fviz_nbclust(scaled_df, kmeans, method = "wss",print.summary=TRUE) +
geom_vline(xintercept = 6, linetype = 2)+
labs(subtitle = "Elbow method")
# Silhouette method
fviz_nbclust(scaled_df, kmeans, method = "silhouette")+
labs(subtitle = "Silhouette method")
# Gap statistic
# nboot = 50 to keep the function speedy.
# recommended value: nboot= 500 for your analysis.
# Use verbose = FALSE to hide computing progression.
#set.seed(1)
#fviz_nbclust(scaled_df, kmeans, nstart = 25,  method = "gap_stat", nboot = 50)+
#  labs(subtitle = "Gap statistic method")
summary(fviz_nbclust(scaled_df, kmeans, method = "wss",print.summary=TRUE))
knitr::opts_chunk$set(echo = TRUE)
#library(dplyr)
library(ggplot2)
library(hexbin)
library(RColorBrewer)
library(ggrepel)
library(ggfortify)
library(extrafont)
library(factoextra)
A_df=read.csv("Data/Study_A.csv")
B_df=read.csv("Data/Study_B.csv")
C_df=read.csv("Data/Study_C.csv")
D_df=read.csv("Data/Study_D.csv")
E_df=read.csv("Data/Study_E.csv")
summary(A_df)
A_df = subset(A_df, VisitDay==0)
B_df = subset(B_df, VisitDay==0)
C_df = subset(C_df, VisitDay==0)
D_df = subset(D_df, VisitDay==0)
E_df = subset(E_df, VisitDay==0)
A_sub = A_df[ , -which(names(A_df) %in% c("Study","Country","PatientID","SiteID","RaterID","AssessmentiD","TxGroup","VisitDay","PANSS_Total","LeadStatus"))]
B_sub = B_df[ , -which(names(B_df) %in% c("Study","Country","PatientID","SiteID","RaterID","AssessmentiD","TxGroup","VisitDay","PANSS_Total","LeadStatus"))]
C_sub = C_df[ , -which(names(C_df) %in% c("Study","Country","PatientID","SiteID","RaterID","AssessmentiD","TxGroup","VisitDay","PANSS_Total","LeadStatus"))]
D_sub = D_df[ , -which(names(D_df) %in% c("Study","Country","PatientID","SiteID","RaterID","AssessmentiD","TxGroup","VisitDay","PANSS_Total","LeadStatus"))]
E_sub = E_df[ , -which(names(E_df) %in% c("Study","Country","PatientID","SiteID","RaterID","AssessmentiD","TxGroup","VisitDay","PANSS_Total","LeadStatus"))]
names(A_sub)
combined_df = rbind(A_sub,B_sub,C_sub,D_sub,E_sub)
A_scale = scale(A_sub)
B_scale = scale(B_sub)
C_scale = scale(C_sub)
D_scale = scale(D_sub)
E_scale = scale(E_sub)
scaled_df = scale(combined_df)
summary(scaled_df)
# Elbow method
fviz_nbclust(scaled_df, kmeans, method = "wss",print.summary=TRUE) +
geom_vline(xintercept = 6, linetype = 2)+
labs(subtitle = "Elbow method")
# Silhouette method
fviz_nbclust(scaled_df, kmeans, method = "silhouette")+
labs(subtitle = "Silhouette method")
# Gap statistic
# nboot = 50 to keep the function speedy.
# recommended value: nboot= 500 for your analysis.
# Use verbose = FALSE to hide computing progression.
#set.seed(1)
#fviz_nbclust(scaled_df, kmeans, nstart = 25,  method = "gap_stat", nboot = 50)+
#  labs(subtitle = "Gap statistic method")
set.seed(1)
km.out = kmeans(scaled_df, 6, nstart =50)
km.clusters =km.out$cluster
km.out$tot.withinss # total within-cluster sum of squares
km.out$withinss # within-cluster sum of squares
km.out$size # cluster size
#km.out$centers # cluster means
fviz_cluster(km.out, scaled_df,geom = c("point"))
#require(cluster)
pam.res <- pam(scaled_df, 6)
knitr::opts_chunk$set(echo = TRUE)
#library(dplyr)
library(ggplot2)
library(hexbin)
library(RColorBrewer)
library(ggrepel)
library(ggfortify)
library(extrafont)
library(factoextra)
A_df=read.csv("Data/Study_A.csv")
B_df=read.csv("Data/Study_B.csv")
C_df=read.csv("Data/Study_C.csv")
D_df=read.csv("Data/Study_D.csv")
E_df=read.csv("Data/Study_E.csv")
summary(A_df)
A_df = subset(A_df, VisitDay==0)
B_df = subset(B_df, VisitDay==0)
C_df = subset(C_df, VisitDay==0)
D_df = subset(D_df, VisitDay==0)
E_df = subset(E_df, VisitDay==0)
A_sub = A_df[ , -which(names(A_df) %in% c("Study","Country","PatientID","SiteID","RaterID","AssessmentiD","TxGroup","VisitDay","PANSS_Total","LeadStatus"))]
B_sub = B_df[ , -which(names(B_df) %in% c("Study","Country","PatientID","SiteID","RaterID","AssessmentiD","TxGroup","VisitDay","PANSS_Total","LeadStatus"))]
C_sub = C_df[ , -which(names(C_df) %in% c("Study","Country","PatientID","SiteID","RaterID","AssessmentiD","TxGroup","VisitDay","PANSS_Total","LeadStatus"))]
D_sub = D_df[ , -which(names(D_df) %in% c("Study","Country","PatientID","SiteID","RaterID","AssessmentiD","TxGroup","VisitDay","PANSS_Total","LeadStatus"))]
E_sub = E_df[ , -which(names(E_df) %in% c("Study","Country","PatientID","SiteID","RaterID","AssessmentiD","TxGroup","VisitDay","PANSS_Total","LeadStatus"))]
names(A_sub)
combined_df = rbind(A_sub,B_sub,C_sub,D_sub,E_sub)
A_scale = scale(A_sub)
B_scale = scale(B_sub)
C_scale = scale(C_sub)
D_scale = scale(D_sub)
E_scale = scale(E_sub)
scaled_df = scale(combined_df)
summary(scaled_df)
# Elbow method
fviz_nbclust(scaled_df, kmeans, method = "wss",print.summary=TRUE) +
geom_vline(xintercept = 6, linetype = 2)+
labs(subtitle = "Elbow method")
# Silhouette method
fviz_nbclust(scaled_df, kmeans, method = "silhouette")+
labs(subtitle = "Silhouette method")
# Gap statistic
# nboot = 50 to keep the function speedy.
# recommended value: nboot= 500 for your analysis.
# Use verbose = FALSE to hide computing progression.
#set.seed(1)
#fviz_nbclust(scaled_df, kmeans, nstart = 25,  method = "gap_stat", nboot = 50)+
#  labs(subtitle = "Gap statistic method")
set.seed(1)
km.out = kmeans(scaled_df, 5, nstart =50)
km.clusters =km.out$cluster
km.out$tot.withinss # total within-cluster sum of squares
km.out$withinss # within-cluster sum of squares
km.out$size # cluster size
#km.out$centers # cluster means
fviz_cluster(km.out, scaled_df,geom = c("point"))
#require(cluster)
pam.res <- pam(scaled_df, 5)
set.seed(1)
km.out = kmeans(scaled_df, 4, nstart =50)
km.clusters =km.out$cluster
km.out$tot.withinss # total within-cluster sum of squares
km.out$withinss # within-cluster sum of squares
km.out$size # cluster size
#km.out$centers # cluster means
fviz_cluster(km.out, scaled_df,geom = c("point"))
NbClust(data = scaled_df, distance = "euclidean", min.nc = 2, max.nc = 10, method = "kmeans")
install.packages("NbClust")
#library(dplyr)
library(ggplot2)
library(hexbin)
library(RColorBrewer)
library(ggrepel)
library(ggfortify)
library(extrafont)
library(factoextra)
library(NbClust)
NbClust(data = scaled_df, distance = "euclidean", min.nc = 2, max.nc = 10, method = "kmeans")
set.seed(1)
km.out = kmeans(scaled_df, 4, nstart =50)
km.clusters =km.out$cluster
km.out$tot.withinss # total within-cluster sum of squares
km.out$withinss # within-cluster sum of squares
km.out$size # cluster size
#km.out$centers # cluster means
set.seed(1)
km.out = kmeans(scaled_df, 4, nstart =50)
km.clusters =km.out$cluster
km.out$tot.withinss # total within-cluster sum of squares
km.out$withinss # within-cluster sum of squares
km.out$size # cluster size
#km.out$centers # cluster means
fviz_cluster(km.out, scaled_df,geom = c("point"))
#require(cluster)
pam.res <- pam(scaled_df, 4)
#library(dplyr)
library(ggplot2)
library(hexbin)
library(RColorBrewer)
library(ggrepel)
library(ggfortify)
library(extrafont)
library(factoextra)
library(NbClust)
library(cluster)
pam.res <- pam(scaled_df, 4)
# Visualize pam clustering
fviz_cluster(pam.res, geom = "point", ellipse.type = "norm")
pam.res <- pam(scaled_df, 4)
# Visualize pam clustering
fviz_cluster(pam.res, geom = "point")
set.seed(1)
chosen_k = 4
km.out = kmeans(scaled_df, chosen_k, nstart =50)
km.clusters =km.out$cluster
km.out$tot.withinss # total within-cluster sum of squares
km.out$withinss # within-cluster sum of squares
km.out$size # cluster size
#km.out$centers # cluster means
fviz_cluster(km.out, scaled_df,geom = c("point"))
pam.res <- pam(scaled_df, chosen_k)
# Visualize pam clustering
fviz_cluster(pam.res, geom = "point")
set.seed(1)
chosen_k = 3
km.out = kmeans(scaled_df, chosen_k, nstart =50)
km.clusters =km.out$cluster
km.out$tot.withinss # total within-cluster sum of squares
km.out$withinss # within-cluster sum of squares
km.out$size # cluster size
#km.out$centers # cluster means
fviz_cluster(km.out, scaled_df,geom = c("point"))
pam.res <- pam(scaled_df, chosen_k)
# Visualize pam clustering
fviz_cluster(pam.res, geom = "point")
set.seed(1)
chosen_k = 2
km.out = kmeans(scaled_df, chosen_k, nstart =50)
km.clusters =km.out$cluster
km.out$tot.withinss # total within-cluster sum of squares
km.out$withinss # within-cluster sum of squares
km.out$size # cluster size
#km.out$centers # cluster means
fviz_cluster(km.out, scaled_df,geom = c("point"))
pam.res <- pam(scaled_df, chosen_k)
# Visualize pam clustering
fviz_cluster(pam.res, geom = "point")
cvalid.out = clValid(scaled_df, nClust = 2:6, clMethods = c("kmeans","pam"), validation = "internal")
#library(dplyr)
library(ggplot2)
library(hexbin)
library(RColorBrewer)
library(ggrepel)
library(ggfortify)
library(extrafont)
library(factoextra)
library(NbClust)
library(cluster)
library(cvalid)
#library(dplyr)
library(ggplot2)
library(hexbin)
library(RColorBrewer)
library(ggrepel)
library(ggfortify)
library(extrafont)
library(factoextra)
library(NbClust)
library(cluster)
library(clvalid)
install.packages("clValid")
#library(dplyr)
library(ggplot2)
library(hexbin)
library(RColorBrewer)
library(ggrepel)
library(ggfortify)
library(extrafont)
library(factoextra)
library(NbClust)
library(cluster)
library(clValid)
cvalid.out = clValid(scaled_df, nClust = 2:6, clMethods = c("kmeans","pam"), validation = "internal")
summary(cvalid.out)
pam.res <- pam(scaled_df, 4)
# Visualize pam clustering
fviz_cluster(pam.res, geom = "point")
pam.res <- pam(scaled_df, 2)
# Visualize pam clustering
fviz_cluster(pam.res, geom = "point")
set.seed(1)
chosen_k = 4
km.out = kmeans(scaled_df, chosen_k, nstart =50)
km.clusters =km.out$cluster
km.out$tot.withinss # total within-cluster sum of squares
km.out$withinss # within-cluster sum of squares
km.out$size # cluster size
#km.out$centers # cluster means
fviz_cluster(km.out, scaled_df,geom = c("point"))
set.seed(1)
chosen_k = 2
km.out = kmeans(scaled_df, chosen_k, nstart =50)
km.clusters =km.out$cluster
km.out$tot.withinss # total within-cluster sum of squares
km.out$withinss # within-cluster sum of squares
km.out$size # cluster size
#km.out$centers # cluster means
fviz_cluster(km.out, scaled_df,geom = c("point"))
set.seed(1)
chosen_k = 3
km.out = kmeans(scaled_df, chosen_k, nstart =50)
km.clusters =km.out$cluster
km.out$tot.withinss # total within-cluster sum of squares
km.out$withinss # within-cluster sum of squares
km.out$size # cluster size
#km.out$centers # cluster means
fviz_cluster(km.out, scaled_df,geom = c("point"))
set.seed(1)
chosen_k = 2
km.out = kmeans(scaled_df, chosen_k, nstart =50)
km.clusters =km.out$cluster
km.out$tot.withinss # total within-cluster sum of squares
km.out$withinss # within-cluster sum of squares
km.out$size # cluster size
#km.out$centers # cluster means
fviz_cluster(km.out, scaled_df,geom = c("point"))
pam.res <- pam(scaled_df, 2)
# Visualize pam clustering
fviz_cluster(pam.res, geom = "point")
pam.res <- pam(scaled_df, 4)
# Visualize pam clustering
fviz_cluster(pam.res, geom = "point")
pam.res <- pam(scaled_df, 3)
# Visualize pam clustering
fviz_cluster(pam.res, geom = "point")
pam.res <- pam(scaled_df, 2)
# Visualize pam clustering
fviz_cluster(pam.res, geom = "point")
