for(i in 1:nrow(hyper_grid)) {
# reproducibility
set.seed(123)
# train model
gbm.tune <- gbm(
formula = PANSS_Total ~ .,
distribution = "gaussian",
data = random_training_df,
n.trees = 10000,
interaction.depth = hyper_grid$interaction.depth[i],
shrinkage = hyper_grid$shrinkage[i],
n.minobsinnode = hyper_grid$n.minobsinnode[i],
bag.fraction = hyper_grid$bag.fraction[i],
train.fraction = .75,
n.cores = NULL, # will use all cores by default
verbose = FALSE
)
# add min training error and trees to grid
hyper_grid$optimal_trees[i] <- which.min(gbm.tune$valid.error)
hyper_grid$min_RMSE[i] <- sqrt(min(gbm.tune$valid.error))
}
# create hyperparameter grid
hyper_grid <- expand.grid(
shrinkage = c(.01, .1, .3),
interaction.depth = c(1, 3, 5),
n.minobsinnode = c(5, 10, 15),
bag.fraction = c(.65, .8, 1),    # introduce stochastic gradient descent by allowing bag.fraction < 1
optimal_trees = 0,               # a place to dump results
min_RMSE = 0                     # a place to dump results
)
# total number of combinations
nrow(hyper_grid)
# randomize data
random_index <- sample(1:nrow(training_df), nrow(training_df))
random_training_df <- training_df[random_index, ]
# grid search
for(i in 1:nrow(hyper_grid)) {
# reproducibility
set.seed(123)
# train model
gbm.tune <- gbm(
formula = PANSS_Total ~ .,
distribution = "gaussian",
data = random_training_df,
n.trees = 5000,
interaction.depth = hyper_grid$interaction.depth[i],
shrinkage = hyper_grid$shrinkage[i],
n.minobsinnode = hyper_grid$n.minobsinnode[i],
bag.fraction = hyper_grid$bag.fraction[i],
train.fraction = .75,
n.cores = NULL, # will use all cores by default
verbose = FALSE
)
# add min training error and trees to grid
hyper_grid$optimal_trees[i] <- which.min(gbm.tune$valid.error)
hyper_grid$min_RMSE[i] <- sqrt(min(gbm.tune$valid.error))
}
install.packages("vtreat")
# create hyperparameter grid
hyper_grid <- expand.grid(
shrinkage = c(.01, .1, .3),
interaction.depth = c(1, 3, 5),
n.minobsinnode = c(5, 10, 15),
bag.fraction = c(.65, .8, 1),    # introduce stochastic gradient descent by allowing bag.fraction < 1
optimal_trees = 0,               # a place to dump results
min_RMSE = 0                     # a place to dump results
)
# total number of combinations
nrow(hyper_grid)
# randomize data
random_index <- sample(1:nrow(training_df), nrow(training_df))
random_training_df <- training_df[random_index, ]
# grid search
for(i in 1:nrow(hyper_grid)) {
# reproducibility
set.seed(123)
# train model
gbm.tune <- gbm(
formula = PANSS_Total ~ .,
distribution = "gaussian",
data = random_training_df,
n.trees = 5000,
interaction.depth = hyper_grid$interaction.depth[i],
shrinkage = hyper_grid$shrinkage[i],
n.minobsinnode = hyper_grid$n.minobsinnode[i],
bag.fraction = hyper_grid$bag.fraction[i],
train.fraction = .75,
n.cores = NULL, # will use all cores by default
verbose = FALSE
)
# add min training error and trees to grid
hyper_grid$optimal_trees[i] <- which.min(gbm.tune$valid.error)
hyper_grid$min_RMSE[i] <- sqrt(min(gbm.tune$valid.error))
}
library(h2o)          # a java-based platform
h2o.no_progress()
h2o.init(max_mem_size = "5g")
# create feature names
y <- "PANSS_Total"
x <- setdiff(names(training_df), y)
# turn training set into h2o object
train.h2o <- as.h2o(training_df)
# training basic GBM model with defaults
h2o.fit1 <- h2o.gbm(
x = x,
y = y,
training_frame = train.h2o,
nfolds = 10
)
# assess model results
h2o.fit1
# training basic GBM model with defaults
h2o.fit2 <- h2o.gbm(
x = x,
y = y,
training_frame = train.h2o,
nfolds = 10,
ntrees = 10000,
stopping_rounds = 10,
stopping_tolerance = 0,
seed = 1,
max_runtime_secs = 60*5
)
# model stopped after xx trees
h2o.fit2@parameters$ntrees
# cross validated RMSE
h2o.rmse(h2o.fit2, xval = TRUE)
h2o.rmse(h2o.fit2, xval = TRUE)^2
# random grid search criteria
search_criteria <- list(
strategy = "RandomDiscrete",
stopping_metric = "mse",
stopping_tolerance = 0.005,
stopping_rounds = 10,
max_runtime_secs = 60*5
)
# perform grid search
grid <- h2o.grid(
algorithm = "gbm",
grid_id = "gbm_grid2",
x = x,
y = y,
training_frame = train,
validation_frame = valid,
hyper_params = hyper_grid,
search_criteria = search_criteria, # add search criteria
ntrees = 1000,
stopping_rounds = 10,
stopping_tolerance = 0,
seed = 123
)
# create training & validation sets
split <- h2o.splitFrame(train.h2o, ratios = 0.75)
train <- split[[1]]
valid <- split[[2]]
# create hyperparameter grid
hyper_grid <- list(
max_depth = c(1, 3, 5),
min_rows = c(1, 5, 10),
learn_rate = c(0.01, 0.05, 0.1),
learn_rate_annealing = c(.99, 1),
sample_rate = c(.4, .6, .8, 1),
col_sample_rate = c(.8, .9, 1)
)
# # perform grid search
# grid <- h2o.grid(
#   algorithm = "gbm",
#   grid_id = "gbm_grid1",
#   x = x,
#   y = y,
#   training_frame = train,
#   validation_frame = valid,
#   hyper_params = hyper_grid,
#   ntrees = 5000,
#   stopping_rounds = 10,
#   stopping_tolerance = 0,
#   seed = 123
#   )
#
# # collect the results and sort by our model performance metric of choice
# grid_perf <- h2o.getGrid(
#   grid_id = "gbm_grid1",
#   sort_by = "mse",
#   decreasing = FALSE
#   )
# grid_perf
# random grid search criteria
search_criteria <- list(
strategy = "RandomDiscrete",
stopping_metric = "mse",
stopping_tolerance = 0.005,
stopping_rounds = 10,
max_runtime_secs = 60*5
)
# perform grid search
grid <- h2o.grid(
algorithm = "gbm",
grid_id = "gbm_grid2",
x = x,
y = y,
training_frame = train,
validation_frame = valid,
hyper_params = hyper_grid,
search_criteria = search_criteria, # add search criteria
ntrees = 1000,
stopping_rounds = 10,
stopping_tolerance = 0,
seed = 123
)
# random grid search criteria
search_criteria <- list(
strategy = "RandomDiscrete",
stopping_metric = "mse",
stopping_tolerance = 0.005,
stopping_rounds = 10,
max_runtime_secs = 60*1 # limit how long it runs
)
# perform grid search
grid <- h2o.grid(
algorithm = "gbm",
grid_id = "gbm_grid2",
x = x,
y = y,
training_frame = train,
validation_frame = valid,
hyper_params = hyper_grid,
search_criteria = search_criteria, # add search criteria
ntrees = 1000,
stopping_rounds = 10,
stopping_tolerance = 0,
seed = 123
)
library(h2o)          # a java-based platform
h2o.no_progress()
h2o.init(max_mem_size = "5g")
library(h2o)          # a java-based platform
h2o.no_progress()
h2o.init(max_mem_size = "5g")
# create feature names
y <- "PANSS_Total"
x <- setdiff(names(training_df), y)
# turn training set into h2o object
train.h2o <- as.h2o(training_df)
# training basic GBM model with defaults
h2o.fit1 <- h2o.gbm(
x = x,
y = y,
training_frame = train.h2o,
nfolds = 10
)
# assess model results
h2o.fit1
# random grid search criteria
search_criteria <- list(
strategy = "RandomDiscrete",
stopping_metric = "mse",
stopping_tolerance = 0.005,
stopping_rounds = 10,
max_runtime_secs = 60*1 # limit how long it runs
)
# perform grid search
grid <- h2o.grid(
algorithm = "gbm",
grid_id = "gbm_grid2",
x = x,
y = y,
training_frame = train,
validation_frame = valid,
hyper_params = hyper_grid,
search_criteria = search_criteria, # add search criteria
ntrees = 1000,
stopping_rounds = 10,
stopping_tolerance = 0,
seed = 123
)
# collect the results and sort by our model performance metric of choice
grid_perf <- h2o.getGrid(
grid_id = "gbm_grid2",
sort_by = "mse",
decreasing = FALSE
)
grid_perf
# random grid search criteria
search_criteria <- list(
strategy = "RandomDiscrete",
stopping_metric = "mse",
stopping_tolerance = 0.005,
stopping_rounds = 10,   # stop if 10 consecutive trees have no improvement
max_runtime_secs = 60*5 # limit how long it runs
)
# perform grid search
grid <- h2o.grid(
algorithm = "gbm",
grid_id = "gbm_grid2",
x = x,
y = y,
training_frame = train,
validation_frame = valid,
hyper_params = hyper_grid,
search_criteria = search_criteria, # add search criteria
ntrees = 1000,
stopping_rounds = 10,
stopping_tolerance = 0,
seed = 123
)
# collect the results and sort by our model performance metric of choice
grid_perf <- h2o.getGrid(
grid_id = "gbm_grid2",
sort_by = "mse",
decreasing = FALSE
)
grid_perf
library(h2o)          # a java-based platform
h2o.no_progress()
h2o.init(max_mem_size = "5g")
# create feature names
y <- "PANSS_Total"
x <- setdiff(names(training_df), y)
# turn training set into h2o object
train.h2o <- as.h2o(training_df)
# training basic GBM model with defaults
h2o.fit1 <- h2o.gbm(
x = x,
y = y,
training_frame = train.h2o,
nfolds = 10
)
# assess model results
h2o.fit1
# create training & validation sets
split <- h2o.splitFrame(train.h2o, ratios = 0.75)
train <- split[[1]]
valid <- split[[2]]
# create hyperparameter grid
hyper_grid <- list(
max_depth = c(1, 3, 5),
min_rows = c(1, 5, 10),
learn_rate = c(0.01, 0.05, 0.1),
learn_rate_annealing = c(.99, 1),
sample_rate = c(.4, .6, .8, 1),
col_sample_rate = c(.8, .9, 1)
)
# # perform grid search
# grid <- h2o.grid(
#   algorithm = "gbm",
#   grid_id = "gbm_grid1",
#   x = x,
#   y = y,
#   training_frame = train,
#   validation_frame = valid,
#   hyper_params = hyper_grid,
#   ntrees = 5000,
#   stopping_rounds = 10,
#   stopping_tolerance = 0,
#   seed = 123
#   )
#
# # collect the results and sort by our model performance metric of choice
# grid_perf <- h2o.getGrid(
#   grid_id = "gbm_grid1",
#   sort_by = "mse",
#   decreasing = FALSE
#   )
# grid_perf
# random grid search criteria
search_criteria <- list(
strategy = "RandomDiscrete",
stopping_metric = "mse",
stopping_tolerance = 0.005,
stopping_rounds = 10,   # stop if 10 consecutive trees have no improvement
max_runtime_secs = 60*5 # limit how long it runs
)
# perform grid search
grid <- h2o.grid(
algorithm = "gbm",
grid_id = "gbm_grid2",
x = x,
y = y,
training_frame = train,
validation_frame = valid,
hyper_params = hyper_grid,
search_criteria = search_criteria, # add search criteria
ntrees = 1000,
stopping_rounds = 10,
stopping_tolerance = 0,
seed = 123
)
# collect the results and sort by our model performance metric of choice
grid_perf <- h2o.getGrid(
grid_id = "gbm_grid2",
sort_by = "mse",
decreasing = FALSE
)
grid_perf
1296/62
20*5
# Grab the model_id for the top model, chosen by validation error
best_model_id <- grid_perf@model_ids[[1]]
best_model <- h2o.getModel(best_model_id)
# Now letâ€™s get performance metrics on the best model
h2o.performance(model = best_model, valid = TRUE)
# train final model
h2o.final <- h2o.gbm(
x = x,
y = y,
training_frame = train.h2o,
nfolds = 10,
ntrees = 1000,
learn_rate = 0.1,
learn_rate_annealing = 1,
max_depth = 5,
min_rows = 1,
sample_rate = 0.6,
col_sample_rate = 0.9,
stopping_rounds = 10,
stopping_tolerance = 0,
seed = 1
)
# model stopped after xx trees
h2o.final@parameters$ntrees
# cross validated RMSE
h2o.rmse(h2o.final, xval = TRUE)
h2o.rmse(h2o.final, xval = TRUE)^2
# train final model
h2o.final <- h2o.gbm(
x = x,
y = y,
training_frame = train.h2o,
nfolds = 10,
ntrees = 10000,
learn_rate = 0.1,
learn_rate_annealing = 1,
max_depth = 5,
min_rows = 1,
sample_rate = 0.6,
col_sample_rate = 0.9,
stopping_rounds = 10,
stopping_tolerance = 0,
seed = 1
)
# train final model
h2o.final <- h2o.gbm(
x = x,
y = y,
training_frame = train.h2o,
nfolds = 10,
ntrees = 5000,
learn_rate = 0.1,
learn_rate_annealing = 1,
max_depth = 5,
min_rows = 1,
sample_rate = 0.6,
col_sample_rate = 0.9,
stopping_rounds = 10,
stopping_tolerance = 0,
seed = 1
)
library(h2o)          # a java-based platform
h2o.no_progress()
h2o.init(max_mem_size = "10g") # have 16g total
# train final model
h2o.final <- h2o.gbm(
x = x,
y = y,
training_frame = train.h2o,
nfolds = 10,
ntrees = 5000,
learn_rate = 0.1,
learn_rate_annealing = 1,
max_depth = 5,
min_rows = 1,
sample_rate = 0.6,
col_sample_rate = 0.9,
stopping_rounds = 10,
stopping_tolerance = 0,
seed = 1
)
# create training & validation sets
split <- h2o.splitFrame(train.h2o, ratios = 0.75)
train <- split[[1]]
valid <- split[[2]]
# create hyperparameter grid
hyper_grid <- list(
max_depth = c(1,5,10),
min_rows = c(1, 5, 10), # minimum observations in a terminal node
learn_rate = c(0.01, 0.05, 0.1),
learn_rate_annealing = c(1),
sample_rate = c(.4, .6, .8, 1),
col_sample_rate = c(.8, .9, 1)
)
# # perform grid search
# grid <- h2o.grid(
#   algorithm = "gbm",
#   grid_id = "gbm_grid1",
#   x = x,
#   y = y,
#   training_frame = train,
#   validation_frame = valid,
#   hyper_params = hyper_grid,
#   ntrees = 5000,
#   stopping_rounds = 10,
#   stopping_tolerance = 0,
#   seed = 123
#   )
#
# # collect the results and sort by our model performance metric of choice
# grid_perf <- h2o.getGrid(
#   grid_id = "gbm_grid1",
#   sort_by = "mse",
#   decreasing = FALSE
#   )
# grid_perf
