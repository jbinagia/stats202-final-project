abline(v = log(cv.out$lambda.1se), col = "red", lty = "dashed")
# most influential variables
coef(cv.out, s = "lambda.1se") %>%
tidy() %>%
filter(row != "(Intercept)") %>%
ggplot(aes(value, reorder(row, value), color = value > 0)) +
geom_point(show.legend = FALSE) +
ggtitle("Influential variables") +
xlab("Coefficient") +
ylab(NULL)
# minimum Ridge MSE
min(ridge.cv.out$cvm)
# minimum Lasso MSE
min(lasso.cv.out$cvm)
plot(ridge.pred,test_df$PANSS_Total)
plot(lasso.pred,test_df$PANSS_Total)
# minimum Ridge MSE
min(ridge.cv.out$cvm)
plot(ridge.pred,test_df$PANSS_Total)
# minimum Lasso MSE
min(lasso.cv.out$cvm)
lot(lasso.pred,test_df$PANSS_Total)
# minimum Ridge MSE
min(ridge.cv.out$cvm)
plot(ridge.pred,test_df$PANSS_Total)
# minimum Lasso MSE
min(lasso.cv.out$cvm)
plot(lasso.pred,test_df$PANSS_Total)
# minimum Ridge MSE
min(ridge.cv.out$cvm)
plot(ridge.pred,test_df$PANSS_Total,xlim=c(20,100), ylim=c(20,100))
# minimum Lasso MSE
min(lasso.cv.out$cvm)
plot(lasso.pred,test_df$PANSS_Total,xlim=c(20,100), ylim=c(20,100))
knitr::opts_chunk$set(echo = TRUE)
rm(list = ls()) # clear global environment
library(h2o)          # a java-based platform
library(plyr)
library(ggplot2)
rm(list = ls()) # clear global environment
A_df=read.csv("Data/Study_A.csv")
B_df=read.csv("Data/Study_B.csv")
C_df=read.csv("Data/Study_C.csv")
D_df=read.csv("Data/Study_D.csv")
E_df=read.csv("Data/Study_E.csv")
summary(E_df)
length(unique(E_df$PatientID))
# # check that there are in fact duplicates
# dfList = list(A_df,B_df,C_df,D_df,E_df)
# for (df in dfList){
#   print(dim(df))
#   print(dim(distinct(df)))
# }
#
# # remove duplicates
# A_df = distinct(A_df)
# B_df = distinct(B_df)
# C_df = distinct(C_df)
# D_df = distinct(D_df)
# E_df = distinct(E_df)
#
# # check disregarding assessment id
# A_df = A_df[ , -which(names(A_df) %in% c("AssessmentiD"))]
# B_df = B_df[ , -which(names(B_df) %in% c("AssessmentiD"))]
# C_df = C_df[ , -which(names(C_df) %in% c("AssessmentiD"))]
# D_df = D_df[ , -which(names(D_df) %in% c("AssessmentiD"))]
# E_df = E_df[ , -which(names(E_df) %in% c("AssessmentiD"))]
#
# for (df in dfList){
#   print(dim(df))
#   print(dim(distinct(df)))
# }
#
# # remove duplicates
# A_df = distinct(A_df)
# B_df = distinct(B_df)
# C_df = distinct(C_df)
# D_df = distinct(D_df)
# E_df = distinct(E_df)
sample_submission_df = read.csv("Data/sample_submission_PANSS.csv")
prediction.patients = sample_submission_df$PatientID # the PatientID #s we should use for Kaggle submission
length(prediction.patients)         # 379 values
length(unique(prediction.patients)) # 379 distinct values
#n_distinct(prediction.patients)   # gives same result
# number.visits = count(E_df, vars = "PatientID")
#
# # Basic barplot
# p<-ggplot(data=number.visits, aes(x=PatientID, y=freq)) +
#   geom_bar(stat="identity") # meaning of stat option: "If you want the heights of the bars to represent values in the data, use stat="identity" and map a value to the y aesthetic."
# p
A_df = subset(A_df, select = c(PatientID, Country, TxGroup, VisitDay, Study,PANSS_Total))
B_df = subset(B_df, select = c(PatientID, Country, TxGroup, VisitDay, Study,PANSS_Total))
C_df = subset(C_df, select = c(PatientID, Country, TxGroup, VisitDay, Study,PANSS_Total))
D_df = subset(D_df, select = c(PatientID, Country, TxGroup, VisitDay, Study,PANSS_Total))
E_df = subset(E_df, select = c(PatientID, Country, TxGroup, VisitDay, Study,PANSS_Total))
# A_df = subset(A_df, select = c(PatientID, Country, VisitDay, Study,PANSS_Total))
# B_df = subset(B_df, select = c(PatientID, Country, VisitDay, Study,PANSS_Total))
# C_df = subset(C_df, select = c(PatientID, Country, VisitDay, Study,PANSS_Total))
# D_df = subset(D_df, select = c(PatientID, Country, VisitDay, Study,PANSS_Total))
# E_df = subset(E_df, select = c(PatientID, Country, VisitDay, Study,PANSS_Total))
combined_df = rbind(A_df,B_df,C_df,D_df,E_df)
summary(combined_df)
for (i in 1:dim(combined_df)[1]) {
id = combined_df[i,"PatientID"]
patient_df = subset(combined_df,PatientID == id)
final.day = max(patient_df$VisitDay)
#if (final.day==0){ # several patients must have dropped out immediately
#  print(combined_df[i,])
#}
combined_df[i,"FinalDay"] = final.day
}
#test_df = combined_df[VisitDay==FinalDay & (PatientID %in% prediction.patients)  , ]
test_df = subset(combined_df, VisitDay==FinalDay & PatientID %in% prediction.patients)
dim(test_df)[1]
for (id in unique(test_df$PatientID)) { # for each unique id
sub_df = subset(test_df, PatientID==id)
if (dim(sub_df)[1]>1){
print(sub_df)
}
}
library(dplyr)
test_df = distinct(test_df)
dim(test_df)[1]
for (id in unique(test_df$PatientID)) { # for each unique id
sub_df = subset(test_df, PatientID==id)
if (dim(sub_df)[1]>1){
print(sub_df)
}
}
pre_test_df = test_df # save what we have so far ... we will exclude this from the total data
library(data.table)
keys <- colnames(test_df)[!grepl('PANSS_Total',colnames(test_df))] # all column names except for PANSS_Total
X <- as.data.table(test_df)
test_df = X[,list(mm=mean(PANSS_Total)),keys]
names(test_df)[length(names(test_df))] = "PANSS_Total"
dim(test_df)
test_df = subset(test_df, select = c(PatientID, Country, TxGroup, VisitDay, Study,PANSS_Total))
#test_df = subset(test_df, select = c(PatientID, Country, VisitDay, Study,PANSS_Total))
forecast_df = test_df
forecast_df = subset(forecast_df, select = c(PatientID, Country, TxGroup, VisitDay, Study))
#forecast_df = subset(forecast_df, select = c(PatientID, Country, VisitDay, Study))
forecast_df$VisitDay = forecast_df$VisitDay + 7
#test_df$VisitDay = scale(test_df$VisitDay)
#test_df$PANSS_Total = scale(test_df$PANSS_Total)
# create "Naive" submission
write.csv(test_df[,c("PatientID","PANSS_Total")],'naive-forecast.csv',row.names=FALSE)
dim(combined_df)
combined_df = anti_join(combined_df, test_df)
dim(combined_df)
training_df = distinct(combined_df)
dim(training_df)[1]
keys <- colnames(training_df)[!grepl('PANSS_Total',colnames(training_df))] # all column names except for PANSS_Total
X <- as.data.table(training_df)
training_df = X[,list(mm=mean(PANSS_Total)),keys]
names(training_df)[length(names(training_df))] = "PANSS_Total"
dim(training_df)
training_df = subset(training_df, select = c(PatientID, Country, TxGroup, VisitDay, Study,PANSS_Total))
#training_df = subset(training_df, select = c(PatientID, Country, VisitDay, Study,PANSS_Total))
#test_df$PatientID = scale(test_df$PatientID)
#test_df$VisitDay = scale(test_df$VisitDay)
#test_df$PANSS_Total = scale(test_df$PANSS_Total)
#training_df = subset(training_df, select = c(PatientID, TxGroup, VisitDay, Study,PANSS_Total))
#test_df = subset(test_df, select = c(PatientID, TxGroup, VisitDay, Study,PANSS_Total))
# Fit a basic MARS model
mars1 <- earth(
PANSS_Total ~ .,
data = training_df
)
library(earth)     # fit MARS models
install.packages("earth")
library(earth)     # fit MARS models
# Fit a basic MARS model
mars1 <- earth(
PANSS_Total ~ .,
data = training_df
)
# Print model summary
print(mars1)
library(earth)     # fit MARS models
# Fit a basic MARS model
mars1 <- earth(
PANSS_Total ~ .,
data = training_df
)
# Print model summary
print(mars1)
summary(mars1) %>% .$coefficients %>% head(10)
library(earth)     # fit MARS models
# Fit a basic MARS model
mars1 <- earth(
PANSS_Total ~ .,
data = training_df
)
# Print model summary
print(mars1)
summary(mars1) %>% .$coefficients %>% head(10)
plot(mars1, which = 1)
# Fit a basic MARS model
mars2 <- earth(
PANSS_Total ~ .,
data = training_df,
degree = 2
)
# check out the first 10 coefficient terms
summary(mars2) %>% .$coefficients %>% head(10)
# Fit a basic MARS model
mars2 <- earth(
PANSS_Total ~ .,
data = training_df,
degree = 2
)
# check out the first 10 coefficient terms
print(mars2)
summary(mars2) %>% .$coefficients %>% head(10)
plot(mars2, which = 1)
# create a tuning grid
hyper_grid <- expand.grid(
degree = 1:3,
nprune = seq(2, 100, length.out = 10) %>% floor()
)
head(hyper_grid)
nprune
# create a tuning grid
hyper_grid <- expand.grid(
degree = 1:3,
nprune = seq(2, 100, length.out = 10) %>% floor()
)
head(hyper_grid)
seq(2, 100, length.out = 10)
# Fit a basic MARS model
mars2 <- earth(
PANSS_Total ~ .,
data = training_df,
degree = 3
)
# check out the first 10 coefficient terms
print(mars2)
summary(mars2) %>% .$coefficients %>% head(10)
plot(mars2, which = 1)
summary(training_df)
library(earth)     # fit MARS models
# Fit a basic MARS model
mars1 <- earth(
PANSS_Total ~ .,
data = training_df[,-"PatientID"]
)
# Print model summary
print(mars1)
summary(mars1) %>% .$coefficients %>% head(10)
plot(mars1, which = 1)
# Fit a basic MARS model
mars2 <- earth(
PANSS_Total ~ .,
data = training_df[,-"PatientID"],
degree = 3
)
# check out the first 10 coefficient terms
print(mars2)
summary(mars2) %>% .$coefficients %>% head(10)
plot(mars2, which = 1)
seq(1, 16, by = 1)
# create a tuning grid
hyper_grid <- expand.grid(
degree = 1:3,
nprune = seq(1, 16, by = 1)
)
head(hyper_grid)
set.seed(1)
# cross validated model
tuned_mars <- train(
x = subset(training_df[,-"PatientID"], select = -PANSS_Total),
y = ames_train$PANSS_Total,
method = "earth",
metric = "MSE",
trControl = trainControl(method = "cv", number = 10),
tuneGrid = hyper_grid
)
set.seed(1)
# cross validated model
tuned_mars <- train(
x = subset(training_df[,-"PatientID"], select = -PANSS_Total),
y = training_df$PANSS_Total,
method = "earth",
metric = "MSE",
trControl = trainControl(method = "cv", number = 10),
tuneGrid = hyper_grid
)
library(caret)
set.seed(1)
# cross validated model
tuned_mars <- train(
x = subset(training_df[,-"PatientID"], select = -PANSS_Total),
y = training_df$PANSS_Total,
method = "earth",
metric = "MSE",
trControl = trainControl(method = "cv", number = 10),
tuneGrid = hyper_grid
)
knitr::opts_chunk$set(echo = TRUE)
rm(list = ls()) # clear global environment
library(h2o)          # a java-based platform
library(plyr)
library(ggplot2)
rm(list = ls()) # clear global environment
A_df=read.csv("Data/Study_A.csv")
B_df=read.csv("Data/Study_B.csv")
C_df=read.csv("Data/Study_C.csv")
D_df=read.csv("Data/Study_D.csv")
E_df=read.csv("Data/Study_E.csv")
summary(E_df)
length(unique(E_df$PatientID))
# # check that there are in fact duplicates
# dfList = list(A_df,B_df,C_df,D_df,E_df)
# for (df in dfList){
#   print(dim(df))
#   print(dim(distinct(df)))
# }
#
# # remove duplicates
# A_df = distinct(A_df)
# B_df = distinct(B_df)
# C_df = distinct(C_df)
# D_df = distinct(D_df)
# E_df = distinct(E_df)
#
# # check disregarding assessment id
# A_df = A_df[ , -which(names(A_df) %in% c("AssessmentiD"))]
# B_df = B_df[ , -which(names(B_df) %in% c("AssessmentiD"))]
# C_df = C_df[ , -which(names(C_df) %in% c("AssessmentiD"))]
# D_df = D_df[ , -which(names(D_df) %in% c("AssessmentiD"))]
# E_df = E_df[ , -which(names(E_df) %in% c("AssessmentiD"))]
#
# for (df in dfList){
#   print(dim(df))
#   print(dim(distinct(df)))
# }
#
# # remove duplicates
# A_df = distinct(A_df)
# B_df = distinct(B_df)
# C_df = distinct(C_df)
# D_df = distinct(D_df)
# E_df = distinct(E_df)
sample_submission_df = read.csv("Data/sample_submission_PANSS.csv")
prediction.patients = sample_submission_df$PatientID # the PatientID #s we should use for Kaggle submission
length(prediction.patients)         # 379 values
length(unique(prediction.patients)) # 379 distinct values
#n_distinct(prediction.patients)   # gives same result
# number.visits = count(E_df, vars = "PatientID")
#
# # Basic barplot
# p<-ggplot(data=number.visits, aes(x=PatientID, y=freq)) +
#   geom_bar(stat="identity") # meaning of stat option: "If you want the heights of the bars to represent values in the data, use stat="identity" and map a value to the y aesthetic."
# p
A_df = subset(A_df, select = c(PatientID, Country, TxGroup, VisitDay, Study,PANSS_Total))
B_df = subset(B_df, select = c(PatientID, Country, TxGroup, VisitDay, Study,PANSS_Total))
C_df = subset(C_df, select = c(PatientID, Country, TxGroup, VisitDay, Study,PANSS_Total))
D_df = subset(D_df, select = c(PatientID, Country, TxGroup, VisitDay, Study,PANSS_Total))
E_df = subset(E_df, select = c(PatientID, Country, TxGroup, VisitDay, Study,PANSS_Total))
# A_df = subset(A_df, select = c(PatientID, Country, VisitDay, Study,PANSS_Total))
# B_df = subset(B_df, select = c(PatientID, Country, VisitDay, Study,PANSS_Total))
# C_df = subset(C_df, select = c(PatientID, Country, VisitDay, Study,PANSS_Total))
# D_df = subset(D_df, select = c(PatientID, Country, VisitDay, Study,PANSS_Total))
# E_df = subset(E_df, select = c(PatientID, Country, VisitDay, Study,PANSS_Total))
combined_df = rbind(A_df,B_df,C_df,D_df,E_df)
summary(combined_df)
for (i in 1:dim(combined_df)[1]) {
id = combined_df[i,"PatientID"]
patient_df = subset(combined_df,PatientID == id)
final.day = max(patient_df$VisitDay)
#if (final.day==0){ # several patients must have dropped out immediately
#  print(combined_df[i,])
#}
combined_df[i,"FinalDay"] = final.day
}
#test_df = combined_df[VisitDay==FinalDay & (PatientID %in% prediction.patients)  , ]
test_df = subset(combined_df, VisitDay==FinalDay & PatientID %in% prediction.patients)
dim(test_df)[1]
for (id in unique(test_df$PatientID)) { # for each unique id
sub_df = subset(test_df, PatientID==id)
if (dim(sub_df)[1]>1){
print(sub_df)
}
}
library(dplyr)
test_df = distinct(test_df)
dim(test_df)[1]
for (id in unique(test_df$PatientID)) { # for each unique id
sub_df = subset(test_df, PatientID==id)
if (dim(sub_df)[1]>1){
print(sub_df)
}
}
pre_test_df = test_df # save what we have so far ... we will exclude this from the total data
library(data.table)
keys <- colnames(test_df)[!grepl('PANSS_Total',colnames(test_df))] # all column names except for PANSS_Total
X <- as.data.table(test_df)
test_df = X[,list(mm=mean(PANSS_Total)),keys]
names(test_df)[length(names(test_df))] = "PANSS_Total"
dim(test_df)
test_df = subset(test_df, select = c(PatientID, Country, TxGroup, VisitDay, Study,PANSS_Total))
#test_df = subset(test_df, select = c(PatientID, Country, VisitDay, Study,PANSS_Total))
forecast_df = test_df
forecast_df = subset(forecast_df, select = c(PatientID, Country, TxGroup, VisitDay, Study))
#forecast_df = subset(forecast_df, select = c(PatientID, Country, VisitDay, Study))
forecast_df$VisitDay = forecast_df$VisitDay + 7
#test_df$VisitDay = scale(test_df$VisitDay)
#test_df$PANSS_Total = scale(test_df$PANSS_Total)
# create "Naive" submission
write.csv(test_df[,c("PatientID","PANSS_Total")],'naive-forecast.csv',row.names=FALSE)
dim(combined_df)
combined_df = anti_join(combined_df, test_df)
dim(combined_df)
training_df = distinct(combined_df)
dim(training_df)[1]
keys <- colnames(training_df)[!grepl('PANSS_Total',colnames(training_df))] # all column names except for PANSS_Total
X <- as.data.table(training_df)
training_df = X[,list(mm=mean(PANSS_Total)),keys]
names(training_df)[length(names(training_df))] = "PANSS_Total"
dim(training_df)
training_df = subset(training_df, select = c(PatientID, Country, TxGroup, VisitDay, Study,PANSS_Total))
#training_df = subset(training_df, select = c(PatientID, Country, VisitDay, Study,PANSS_Total))
#test_df$PatientID = scale(test_df$PatientID)
#test_df$VisitDay = scale(test_df$VisitDay)
#test_df$PANSS_Total = scale(test_df$PANSS_Total)
#training_df = subset(training_df, select = c(PatientID, TxGroup, VisitDay, Study,PANSS_Total))
#test_df = subset(test_df, select = c(PatientID, TxGroup, VisitDay, Study,PANSS_Total))
library(earth)     # fit MARS models
# Fit a basic MARS model
mars1 <- earth(
PANSS_Total ~ .,
data = training_df[,-"PatientID"]
)
# Print model summary
print(mars1)
summary(mars1) %>% .$coefficients %>% head(10)
plot(mars1, which = 1)
# Fit a basic MARS model
mars2 <- earth(
PANSS_Total ~ .,
data = training_df[,-"PatientID"],
degree = 3
)
# check out the first 10 coefficient terms
print(mars2)
summary(mars2) %>% .$coefficients %>% head(10)
plot(mars2, which = 1)
# create a tuning grid
hyper_grid <- expand.grid(
degree = 1:3,
nprune = seq(1, 16, by = 2)
)
head(hyper_grid)
library(caret)
set.seed(1)
# cross validated model
tuned_mars <- train(
x = subset(training_df[,-"PatientID"], select = -PANSS_Total),
y = training_df$PANSS_Total,
method = "earth",
metric = "RMSE",
trControl = trainControl(method = "cv", number = 10),
tuneGrid = hyper_grid
)
# best model
tuned_mars$bestTune
##    nprune degree
## 14     34      2
# plot results
ggplot(tuned_mars)
summary(tuned_mars)
# variable importance plots
p1 <- vip(tuned_mars, num_features = 40, bar = FALSE, value = "gcv") + ggtitle("GCV")
library(vip)       # variable importance
install.packages("vip")
library(vip)       # variable importance
# variable importance plots
p1 <- vip(tuned_mars, num_features = 40, bar = FALSE, value = "gcv") + ggtitle("GCV")
p2 <- vip(tuned_mars, num_features = 40, bar = FALSE, value = "rss") + ggtitle("RSS")
gridExtra::grid.arrange(p1, p2, ncol = 2)
predict(tuned_mars,test_df)
mean((test_df$PANSS_Total - predict(tuned_mars, test_df))^2)
mean((test_df$PANSS_Total - predict(tuned_mars, test_df))^2)
prediction = predict(tuned_mars, forecast_df)
write.csv(prediction,'mars-forecast.csv',row.names=FALSE)
mean((test_df$PANSS_Total - predict(tuned_mars, test_df))^2)
forecast_df$prediction = predict(tuned_mars, forecast_df)
write.csv(prediction,'mars-forecast.csv',row.names=FALSE)
forecast_df
mean((test_df$PANSS_Total - predict(tuned_mars, test_df))^2)
forecast_df$prediction = predict(tuned_mars, forecast_df)
write.csv(forecast_df[,c("PatientID","prediction")],'mars-forecast.csv',row.names=FALSE)
test_predict = predict(tuned_mars, test_df)
mean((test_df$PANSS_Total - test_predict)^2)
plot(as.vector(test_predict), test_df$PANSS_Total,xlim=c(30,100), ylim=c(30,100))
abline(0,1)
forecast_df$prediction = predict(tuned_mars, forecast_df)
write.csv(forecast_df[,c("PatientID","prediction")],'mars-forecast.csv',row.names=FALSE)
histogram(test_df$PANSS_Total)
plot(test_df$VisitDay,test_df$PANSS_Total)
plot(E_df$VisitDay,E_df$PANSS_Total)
plot(combined_df$VisitDay,combined_df$PANSS_Total)
plot(test_df$VisitDay,log(test_df$PANSS_Total)
ad
plot(test_df$VisitDay,log(test_df$PANSS_Total))
names(forecast_df)
test_predict = predict(tuned_mars, test_df)
mean((test_df$PANSS_Total - test_predict)^2)
plot(as.vector(test_predict), test_df$PANSS_Total,xlim=c(30,100), ylim=c(30,100))
abline(0,1)
forecast_df$PANSS_Total = predict(tuned_mars, forecast_df)
write.csv(forecast_df[,c("PatientID","PANSS_Total")],'mars-forecast.csv',row.names=FALSE)
