scaled_df = scale(combined_df)
summary(scaled_df)
#cvalid.out = clValid(scaled_df, maxitems = 3000, nClust = 2:8, clMethods = c("kmeans","pam"), validation = c("internal", "stability"))
#summary(cvalid.out)
# Elbow method
fviz_nbclust(scaled_df, kmeans, method = "wss",print.summary=TRUE) +
geom_vline(xintercept = 2, linetype = 2)+
#labs(subtitle = "Elbow method") +
labs(title = "",subtitle = "") + # for the figure in the report
ggsave("Figures/k-means-elbow.png",width=3,height=3,units="in",device="png",dpi="retina")
# Silhouette method
fviz_nbclust(scaled_df, kmeans, method = "silhouette")+
#labs(subtitle = "Silhouette method")
labs(title = "",subtitle = "") + # for the figure in the report
ggsave("Figures/k-means-silhouette.png",width=3,height=3,units="in",device="png",dpi="retina")
# Gap statistic
# nboot = 50 to keep the function speedy. Number of Monte Carlo ("bootstrap") samples.
# recommended value: nboot= 500 for your analysis.
# Use verbose = FALSE to hide computing progression.
# set.seed(1)
#gc()
#fviz_nbclust(scaled_df, kmeans,k.max = 8,iter.max=30,nstart = 25,method="gap_stat",nboot = 50)+ labs(subtitle = "Gap statistic method")
#ggsave("Figures/k-means-gap-statistic.png",width=6,height=4,units="in",device="png",dpi="retina")
# NbClust(data = scaled_df, distance = "euclidean", min.nc = 2, max.nc = 10, method = "kmeans");
set.seed(1)
chosen_k = 2
km.out = kmeans(scaled_df, chosen_k, nstart = 50)
km.clusters =km.out$cluster
# stats
km.out$tot.withinss # total within-cluster sum of squares
km.out$withinss # within-cluster sum of squares
km.out$size # cluster size
# visualize
fviz_cluster(km.out, scaled_df,geom = c("point")) + theme_minimal() + labs(title ="")
# Elbow method
fviz_nbclust(scaled_df, pam, method = "wss",print.summary=TRUE) +
geom_vline(xintercept = 2, linetype = 2)+
#labs(subtitle = "Elbow method")
labs(title = "",subtitle = "") + # for the figure in the report
ggsave("Figures/pam-silhouette.png",width=3,height=3,units="in",device="png",dpi="retina")
# Silhouette method
fviz_nbclust(scaled_df, pam, method = "silhouette")+
#labs(subtitle = "Silhouette method")
labs(title = "",subtitle = "") + # for the figure in the report
ggsave("Figures/pam-silhouette.png",width=3,height=3,units="in",device="png",dpi="retina")
# Gap statistic
# nboot = 50 to keep the function speedy. Number of Monte Carlo ("bootstrap") samples.
# recommended value: nboot= 500 for your analysis.
# Use verbose = FALSE to hide computing progression.
# set.seed(1)
fviz_nbclust(scaled_df, k.max = 10, pam,method="gap_stat",nboot = 50)+
labs(subtitle = "Gap statistic method")
ggsave("Figures/pam-gap-statistic.png",width=6,height=4,units="in",device="png",dpi="retina")
ggsave("Figures/pam-elbow.png",width=3,height=3,units="in",device="png",dpi="retina")
fviz_nbclust(scaled_df, pam, method = "wss",print.summary=TRUE) +
geom_vline(xintercept = 2, linetype = 2)+
#labs(subtitle = "Elbow method")
labs(title = "",subtitle = "") + # for the figure in the report
ggsave("Figures/pam-elbow.png",width=3,height=3,units="in",device="png",dpi="retina")
# Elbow method
fviz_nbclust(scaled_df, pam, method = "wss",print.summary=TRUE) +
geom_vline(xintercept = 2, linetype = 2)+
#labs(subtitle = "Elbow method")
labs(title = "",subtitle = "") + # for the figure in the report
ggsave("Figures/pam-elbow.png",width=3,height=3,units="in",device="png",dpi="retina")
# Silhouette method
fviz_nbclust(scaled_df, pam, method = "silhouette")+
#labs(subtitle = "Silhouette method")
labs(title = "",subtitle = "") + # for the figure in the report
ggsave("Figures/pam-silhouette.png",width=3,height=3,units="in",device="png",dpi="retina")
# Gap statistic
# nboot = 50 to keep the function speedy. Number of Monte Carlo ("bootstrap") samples.
# recommended value: nboot= 500 for your analysis.
# Use verbose = FALSE to hide computing progression.
# set.seed(1)
fviz_nbclust(scaled_df, k.max = 10, pam,method="gap_stat",nboot = 50)+
#labs(subtitle = "Gap statistic method")
labs(title = "",subtitle = "") + # for the figure in the report
ggsave("Figures/pam-gap-statistic.png",width=3,height=3,units="in",device="png",dpi="retina")
pam.res <- pam(scaled_df, chosen_k)
# Visualize pam clustering
fviz_cluster(pam.res, geom = "point") + theme_minimal() + labs(title ="")  + theme_minimal() + labs(title ="")
pca.out = prcomp(scaled_df, scale=TRUE)
ggplot2::autoplot(pca.out, label = FALSE, loadings.label = TRUE, repel=TRUE) + theme_minimal()
ggsave("Figures/pca-first.png",width=3,height=3,units="in",device="png",dpi="retina")
pcaCharts <- function(x) {
x.var <- x$sdev ^ 2
x.pvar <- x.var/sum(x.var)
print("proportions of variance:")
print(x.pvar)
par(mfrow=c(2,2))
plot(x.pvar,xlab="Principal component",
ylab="Proportion of variance explained", ylim=c(0,1), type='b')
plot(cumsum(x.pvar),xlab="Principal component",
ylab="Cumulative Proportion of variance explained", ylim=c(0,1), type='b')
screeplot(x)
screeplot(x,type="l")
par(mfrow=c(1,1))
}
# check proportion of variance explained by each component
pcaCharts(pca.out)
pca.out$rotation[,1:3]
res.pca = PCA(scaled_df, graph = FALSE)
print(res.pca)
fviz_screeplot(res.pca, addlabels = TRUE, ylim = c(0, 50))
ggsave("Figures/pca-scree.png",width=3,height=3,units="in",device="png",dpi="retina")
# Graph of variables: default plot
fviz_pca_var(res.pca, col.var="contrib",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
repel = TRUE # Avoid text overlapping
)
ggsave("Figures/pca-variables.png",width=3,height=3,units="in",device="png",dpi="retina")
fviz_pca_ind(res.pca, col.ind = "cos2",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
label = FALSE,
repel = TRUE # Avoid text overlapping (slow if many points)
)
ggsave("Figures/pam-individuals.png",width=3,height=3,units="in",device="png",dpi="retina")
# Contributions of variables to PC1
fviz_contrib(res.pca, choice = "var", axes = 1, top = 10)
# Contributions of variables to PC2
fviz_contrib(res.pca, choice = "var", axes = 2, top = 10)
# Contributions of variables to PC2
fviz_contrib(res.pca, choice = "var", axes = 3, top = 10)
omission_vector = c("Country","PatientID","SiteID","RaterID",
"AssessmentiD","TxGroup","VisitDay","PANSS_Total","LeadStatus")
combined_all_col = rbind(A_df[ , -which(names(A_df) %in% omission_vector)],B_df[ , -which(names(A_df) %in% omission_vector)],C_df[ , -which(names(A_df) %in% omission_vector)],D_df[ , -which(names(A_df) %in% omission_vector)],E_df[ , -which(names(A_df) %in% omission_vector)])
res.pca <- prcomp(combined_all_col[,-1],  scale = TRUE)
fviz(res.pca, "ind", label = "none",habillage=combined_all_col$Study,addEllipses = "True",alpha=0.3,ellipse.type = "convex") # Individuals plot
res.pca <- prcomp(combined_all_col[,-1],  scale = TRUE)
fviz(res.pca, "ind", label = "none",habillage=combined_all_col$Study,addEllipses = "True",alpha=0.3) # Individuals plot
omission_vector = c("Study","PatientID","SiteID","RaterID",
"AssessmentiD","TxGroup","VisitDay","PANSS_Total","LeadStatus")
combined_all_col = rbind(A_df[ , -which(names(A_df) %in% omission_vector)],B_df[ , -which(names(A_df) %in% omission_vector)],C_df[ , -which(names(A_df) %in% omission_vector)],D_df[ , -which(names(A_df) %in% omission_vector)],E_df[ , -which(names(A_df) %in% omission_vector)])
library(plyr)
sort(table(combined_all_col$Country),decreasing=TRUE)
# consider only top 5 countries
countries = c("USA","China","Russia","Japan","Ukraine")
top_5_country_df = subset(combined_all_col, Country %in% countries)
sum(table(top_5_country_df$Country))/sum(table(combined_all_col$Country)) # these countries make up 80%
res.pca <- prcomp(top_5_country_df[,-1],  scale = TRUE)
fviz(res.pca, "ind", label = "none",habillage=top_5_country_df$Country,addEllipses = TRUE,alpha=0.5,ellipse.alpha = 0.25)
# Contributions of variables to PC1
fviz_contrib(res.pca, choice = "var", axes = 1, top = 10)
ggsave("Figures/contribution1-statistic.png",width=3,height=3,units="in",device="png",dpi="retina")
# Contributions of variables to PC2
fviz_contrib(res.pca, choice = "var", axes = 2, top = 10)
ggsave("Figures/contribution2.png",width=3,height=3,units="in",device="png",dpi="retina")
# Contributions of variables to PC2
fviz_contrib(res.pca, choice = "var", axes = 3, top = 10)
# Graph of variables: default plot
fviz_pca_var(res.pca, col.var="contrib",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
repel = TRUE # Avoid text overlapping
)
ggsave("Figures/pca-variables.png",units="in",device="png",dpi="retina")
fviz_pca_ind(res.pca, col.ind = "cos2",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
label = FALSE,
repel = TRUE # Avoid text overlapping (slow if many points)
)
ggsave("Figures/pam-individuals.png",units="in",device="png",dpi="retina")
pca.out = prcomp(scaled_df, scale=TRUE)
ggplot2::autoplot(pca.out, label = FALSE, loadings.label = TRUE, repel=TRUE) + theme_minimal()
ggsave("Figures/pca-first.png",width=3,height=3,units="in",device="png",dpi="retina")
pcaCharts <- function(x) {
x.var <- x$sdev ^ 2
x.pvar <- x.var/sum(x.var)
print("proportions of variance:")
print(x.pvar)
par(mfrow=c(2,2))
plot(x.pvar,xlab="Principal component",
ylab="Proportion of variance explained", ylim=c(0,1), type='b')
plot(cumsum(x.pvar),xlab="Principal component",
ylab="Cumulative Proportion of variance explained", ylim=c(0,1), type='b')
screeplot(x)
screeplot(x,type="l")
par(mfrow=c(1,1))
}
# check proportion of variance explained by each component
pcaCharts(pca.out)
pca.out$rotation[,1:3]
res.pca = PCA(scaled_df, graph = FALSE)
print(res.pca)
fviz_screeplot(res.pca, addlabels = TRUE, ylim = c(0, 50))
ggsave("Figures/pca-scree.png",width=3,height=3,units="in",device="png",dpi="retina")
# Graph of variables: default plot
fviz_pca_var(res.pca, col.var="contrib",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
repel = TRUE # Avoid text overlapping
)
ggsave("Figures/pca-variables.png",units="in",device="png",dpi="retina")
fviz_pca_ind(res.pca, col.ind = "cos2",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
label = FALSE,
repel = TRUE # Avoid text overlapping (slow if many points)
)
ggsave("Figures/pam-individuals.png",units="in",device="png",dpi="retina")
# Contributions of variables to PC1
fviz_contrib(res.pca, choice = "var", axes = 1, top = 10)
ggsave("Figures/contribution1-statistic.png",width=3,height=3,units="in",device="png",dpi="retina")
# Contributions of variables to PC2
fviz_contrib(res.pca, choice = "var", axes = 2, top = 10)
ggsave("Figures/contribution2.png",width=3,height=3,units="in",device="png",dpi="retina")
# Contributions of variables to PC2
fviz_contrib(res.pca, choice = "var", axes = 3, top = 10)
omission_vector = c("Country","PatientID","SiteID","RaterID",
"AssessmentiD","TxGroup","VisitDay","PANSS_Total","LeadStatus")
combined_all_col = rbind(A_df[ , -which(names(A_df) %in% omission_vector)],B_df[ , -which(names(A_df) %in% omission_vector)],C_df[ , -which(names(A_df) %in% omission_vector)],D_df[ , -which(names(A_df) %in% omission_vector)],E_df[ , -which(names(A_df) %in% omission_vector)])
res.pca <- prcomp(combined_all_col[,-1],  scale = TRUE)
fviz(res.pca, "ind", label = "none",habillage=combined_all_col$Study,addEllipses = "True",alpha=0.3,ellipse.type = "convex") # Individuals plot
res.pca <- prcomp(combined_all_col[,-1],  scale = TRUE)
fviz(res.pca, "ind", label = "none",habillage=combined_all_col$Study,addEllipses = "True",alpha=0.3) # Individuals plot
omission_vector = c("Study","PatientID","SiteID","RaterID",
"AssessmentiD","TxGroup","VisitDay","PANSS_Total","LeadStatus")
combined_all_col = rbind(A_df[ , -which(names(A_df) %in% omission_vector)],B_df[ , -which(names(A_df) %in% omission_vector)],C_df[ , -which(names(A_df) %in% omission_vector)],D_df[ , -which(names(A_df) %in% omission_vector)],E_df[ , -which(names(A_df) %in% omission_vector)])
library(plyr)
sort(table(combined_all_col$Country),decreasing=TRUE)
# consider only top 5 countries
countries = c("USA","China","Russia","Japan","Ukraine")
top_5_country_df = subset(combined_all_col, Country %in% countries)
sum(table(top_5_country_df$Country))/sum(table(combined_all_col$Country)) # these countries make up 80%
res.pca <- prcomp(top_5_country_df[,-1],  scale = TRUE)
fviz(res.pca, "ind", label = "none",habillage=top_5_country_df$Country,addEllipses = TRUE,alpha=0.5,ellipse.alpha = 0.25)
# Contributions of variables to PC1
fviz_contrib(res.pca, choice = "var", axes = 1, top = 10)
ggsave("Figures/contribution1.png",width=3,height=3,units="in",device="png",dpi="retina")
# Contributions of variables to PC2
fviz_contrib(res.pca, choice = "var", axes = 2, top = 10)
ggsave("Figures/contribution2.png",width=3,height=3,units="in",device="png",dpi="retina")
# Contributions of variables to PC2
fviz_contrib(res.pca, choice = "var", axes = 3, top = 10)
# Graph of variables: default plot
fviz_pca_var(res.pca, col.var="contrib",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
repel = TRUE # Avoid text overlapping
)
ggsave("Figures/pca-variables.png",units="in",device="png",dpi="retina")
fviz_pca_ind(res.pca, col.ind = "cos2",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
label = FALSE,
repel = TRUE # Avoid text overlapping (slow if many points)
)
ggsave("Figures/pca-individuals.png",units="in",device="png",dpi="retina")
pca.out = prcomp(scaled_df, scale=TRUE)
ggplot2::autoplot(pca.out, label = FALSE, loadings.label = TRUE, repel=TRUE) + theme_minimal()
ggsave("Figures/pca-first.png",width=3,height=3,units="in",device="png",dpi="retina")
pcaCharts <- function(x) {
x.var <- x$sdev ^ 2
x.pvar <- x.var/sum(x.var)
print("proportions of variance:")
print(x.pvar)
par(mfrow=c(2,2))
plot(x.pvar,xlab="Principal component",
ylab="Proportion of variance explained", ylim=c(0,1), type='b')
plot(cumsum(x.pvar),xlab="Principal component",
ylab="Cumulative Proportion of variance explained", ylim=c(0,1), type='b')
screeplot(x)
screeplot(x,type="l")
par(mfrow=c(1,1))
}
# check proportion of variance explained by each component
pcaCharts(pca.out)
pca.out$rotation[,1:3]
res.pca = PCA(scaled_df, graph = FALSE)
print(res.pca)
fviz_screeplot(res.pca, addlabels = TRUE, ylim = c(0, 50))
ggsave("Figures/pca-scree.png",width=3,height=3,units="in",device="png",dpi="retina")
# Graph of variables: default plot
fviz_pca_var(res.pca, col.var="contrib",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
repel = TRUE # Avoid text overlapping
)
ggsave("Figures/pca-variables.png",units="in",device="png",dpi="retina")
fviz_pca_ind(res.pca, col.ind = "cos2",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
label = FALSE,
repel = TRUE # Avoid text overlapping (slow if many points)
)
ggsave("Figures/pca-individuals.png",units="in",device="png",dpi="retina")
# Contributions of variables to PC1
fviz_contrib(res.pca, choice = "var", axes = 1, top = 10)
ggsave("Figures/contribution1.png",width=3,height=3,units="in",device="png",dpi="retina")
# Contributions of variables to PC2
fviz_contrib(res.pca, choice = "var", axes = 2, top = 10)
ggsave("Figures/contribution2.png",width=3,height=3,units="in",device="png",dpi="retina")
# Contributions of variables to PC2
fviz_contrib(res.pca, choice = "var", axes = 3, top = 10)
omission_vector = c("Country","PatientID","SiteID","RaterID",
"AssessmentiD","TxGroup","VisitDay","PANSS_Total","LeadStatus")
combined_all_col = rbind(A_df[ , -which(names(A_df) %in% omission_vector)],B_df[ , -which(names(A_df) %in% omission_vector)],C_df[ , -which(names(A_df) %in% omission_vector)],D_df[ , -which(names(A_df) %in% omission_vector)],E_df[ , -which(names(A_df) %in% omission_vector)])
res.pca <- prcomp(combined_all_col[,-1],  scale = TRUE)
fviz(res.pca, "ind", label = "none",habillage=combined_all_col$Study,addEllipses = "True",alpha=0.3,ellipse.type = "convex") # Individuals plot
res.pca <- prcomp(combined_all_col[,-1],  scale = TRUE)
fviz(res.pca, "ind", label = "none",habillage=combined_all_col$Study,addEllipses = "True",alpha=0.3) # Individuals plot
omission_vector = c("Study","PatientID","SiteID","RaterID",
"AssessmentiD","TxGroup","VisitDay","PANSS_Total","LeadStatus")
combined_all_col = rbind(A_df[ , -which(names(A_df) %in% omission_vector)],B_df[ , -which(names(A_df) %in% omission_vector)],C_df[ , -which(names(A_df) %in% omission_vector)],D_df[ , -which(names(A_df) %in% omission_vector)],E_df[ , -which(names(A_df) %in% omission_vector)])
library(plyr)
sort(table(combined_all_col$Country),decreasing=TRUE)
# consider only top 5 countries
countries = c("USA","China","Russia","Japan","Ukraine")
top_5_country_df = subset(combined_all_col, Country %in% countries)
sum(table(top_5_country_df$Country))/sum(table(combined_all_col$Country)) # these countries make up 80%
res.pca <- prcomp(top_5_country_df[,-1],  scale = TRUE)
fviz(res.pca, "ind", label = "none",habillage=top_5_country_df$Country,addEllipses = TRUE,alpha=0.5,ellipse.alpha = 0.25)
# Contributions of variables to PC1
fviz_contrib(res.pca, choice = "var", axes = 1, top = 10) +
labs(title = "",subtitle = "") + # for the figure in the report
ggsave("Figures/contribution1.png",width=3,height=3,units="in",device="png",dpi="retina")
# Contributions of variables to PC2
fviz_contrib(res.pca, choice = "var", axes = 2, top = 10) +
labs(title = "",subtitle = "") + # for the figure in the report
ggsave("Figures/contribution2.png",width=3,height=3,units="in",device="png",dpi="retina")
# Contributions of variables to PC2
fviz_contrib(res.pca, choice = "var", axes = 3, top = 10)
fviz_screeplot(res.pca, addlabels = TRUE, ylim = c(0, 50))
ggsave("Figures/pca-scree.png",units="in",device="png",dpi="retina")
pca.out = prcomp(scaled_df, scale=TRUE)
ggplot2::autoplot(pca.out, label = FALSE, loadings.label = TRUE, repel=TRUE) + theme_minimal()
ggsave("Figures/pca-first.png",units="in",device="png",dpi="retina")
pcaCharts <- function(x) {
x.var <- x$sdev ^ 2
x.pvar <- x.var/sum(x.var)
print("proportions of variance:")
print(x.pvar)
par(mfrow=c(2,2))
plot(x.pvar,xlab="Principal component",
ylab="Proportion of variance explained", ylim=c(0,1), type='b')
plot(cumsum(x.pvar),xlab="Principal component",
ylab="Cumulative Proportion of variance explained", ylim=c(0,1), type='b')
screeplot(x)
screeplot(x,type="l")
par(mfrow=c(1,1))
}
# check proportion of variance explained by each component
pcaCharts(pca.out)
pca.out$rotation[,1:3]
res.pca = PCA(scaled_df, graph = FALSE)
print(res.pca)
fviz_screeplot(res.pca, addlabels = TRUE, ylim = c(0, 50))
ggsave("Figures/pca-scree.png",units="in",device="png",dpi="retina")
# Graph of variables: default plot
fviz_pca_var(res.pca, col.var="contrib",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
repel = TRUE # Avoid text overlapping
)
ggsave("Figures/pca-variables.png",units="in",device="png",dpi="retina")
fviz_pca_ind(res.pca, col.ind = "cos2",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
label = FALSE,
repel = TRUE # Avoid text overlapping (slow if many points)
)
ggsave("Figures/pca-individuals.png",units="in",device="png",dpi="retina")
# Contributions of variables to PC1
fviz_contrib(res.pca, choice = "var", axes = 1, top = 10) +
labs(title = "",subtitle = "") + # for the figure in the report
ggsave("Figures/contribution1.png",width=3,height=3,units="in",device="png",dpi="retina")
# Contributions of variables to PC2
fviz_contrib(res.pca, choice = "var", axes = 2, top = 10) +
labs(title = "",subtitle = "") + # for the figure in the report
ggsave("Figures/contribution2.png",width=3,height=3,units="in",device="png",dpi="retina")
# Contributions of variables to PC2
fviz_contrib(res.pca, choice = "var", axes = 3, top = 10)
omission_vector = c("Country","PatientID","SiteID","RaterID",
"AssessmentiD","TxGroup","VisitDay","PANSS_Total","LeadStatus")
combined_all_col = rbind(A_df[ , -which(names(A_df) %in% omission_vector)],B_df[ , -which(names(A_df) %in% omission_vector)],C_df[ , -which(names(A_df) %in% omission_vector)],D_df[ , -which(names(A_df) %in% omission_vector)],E_df[ , -which(names(A_df) %in% omission_vector)])
res.pca <- prcomp(combined_all_col[,-1],  scale = TRUE)
fviz(res.pca, "ind", label = "none",habillage=combined_all_col$Study,addEllipses = "True",alpha=0.3,ellipse.type = "convex") # Individuals plot
res.pca <- prcomp(combined_all_col[,-1],  scale = TRUE)
fviz(res.pca, "ind", label = "none",habillage=combined_all_col$Study,addEllipses = "True",alpha=0.3) # Individuals plot
omission_vector = c("Study","PatientID","SiteID","RaterID",
"AssessmentiD","TxGroup","VisitDay","PANSS_Total","LeadStatus")
combined_all_col = rbind(A_df[ , -which(names(A_df) %in% omission_vector)],B_df[ , -which(names(A_df) %in% omission_vector)],C_df[ , -which(names(A_df) %in% omission_vector)],D_df[ , -which(names(A_df) %in% omission_vector)],E_df[ , -which(names(A_df) %in% omission_vector)])
library(plyr)
sort(table(combined_all_col$Country),decreasing=TRUE)
# consider only top 5 countries
countries = c("USA","China","Russia","Japan","Ukraine")
top_5_country_df = subset(combined_all_col, Country %in% countries)
sum(table(top_5_country_df$Country))/sum(table(combined_all_col$Country)) # these countries make up 80%
res.pca <- prcomp(top_5_country_df[,-1],  scale = TRUE)
fviz(res.pca, "ind", label = "none",habillage=top_5_country_df$Country,addEllipses = TRUE,alpha=0.5,ellipse.alpha = 0.25)
# Elbow method
fviz_nbclust(scaled_df, pam, method = "wss",print.summary=TRUE) +
geom_vline(xintercept = 2, linetype = 2)+
#labs(subtitle = "Elbow method")
labs(title = "",subtitle = "") + # for the figure in the report
ggsave("Figures/pam-elbow.png",width=2,height=3,units="in",device="png",dpi="retina")
# Silhouette method
fviz_nbclust(scaled_df, pam, method = "silhouette")+
#labs(subtitle = "Silhouette method")
labs(title = "",subtitle = "") + # for the figure in the report
ggsave("Figures/pam-silhouette.png",width=2,height=3,units="in",device="png",dpi="retina")
# Gap statistic
# nboot = 50 to keep the function speedy. Number of Monte Carlo ("bootstrap") samples.
# recommended value: nboot= 500 for your analysis.
# Use verbose = FALSE to hide computing progression.
# set.seed(1)
#fviz_nbclust(scaled_df, k.max = 10, pam,method="gap_stat",nboot = 50)+
#labs(subtitle = "Gap statistic method")
#  labs(title = "",subtitle = "") + # for the figure in the report
#ggsave("Figures/pam-gap-statistic.png",width=3,height=3,units="in",device="png",dpi="retina")
# Elbow method
fviz_nbclust(scaled_df, pam, method = "wss",print.summary=TRUE) +
geom_vline(xintercept = 2, linetype = 2)+
#labs(subtitle = "Elbow method")
labs(title = "",subtitle = "") + # for the figure in the report
ggsave("Figures/pam-elbow.png",width=2,height=3,units="in",device="png",dpi="retina")
# Silhouette method
fviz_nbclust(scaled_df, pam, method = "silhouette")+
#labs(subtitle = "Silhouette method")
labs(title = "",subtitle = "") + # for the figure in the report
ggsave("Figures/pam-silhouette.png",width=2,height=3,units="in",device="png",dpi="retina")
# Gap statistic
# nboot = 50 to keep the function speedy. Number of Monte Carlo ("bootstrap") samples.
# recommended value: nboot= 500 for your analysis.
# Use verbose = FALSE to hide computing progression.
set.seed(1)
fviz_nbclust(scaled_df, k.max = 10, pam,method="gap_stat",nboot = 50)+
#labs(subtitle = "Gap statistic method")
labs(title = "",subtitle = "") + # for the figure in the report
ggsave("Figures/pam-gap-statistic.png",width=2,height=3,units="in",device="png",dpi="retina")
+
xlab("Dose (mg)")
# Elbow method
fviz_nbclust(scaled_df, pam, method = "wss",print.summary=TRUE) +
geom_vline(xintercept = 2, linetype = 2)+
#labs(subtitle = "Elbow method")
labs(title = "",subtitle = "") + # for the figure in the report
ggsave("Figures/pam-elbow.png",width=2,height=3,units="in",device="png",dpi="retina")
# Silhouette method
fviz_nbclust(scaled_df, pam, method = "silhouette")+
#labs(subtitle = "Silhouette method")
labs(title = "",subtitle = "") + # for the figure in the report
ggsave("Figures/pam-silhouette.png",width=2,height=3,units="in",device="png",dpi="retina")
# Gap statistic
# nboot = 50 to keep the function speedy. Number of Monte Carlo ("bootstrap") samples.
# recommended value: nboot= 500 for your analysis.
# Use verbose = FALSE to hide computing progression.
set.seed(1)
fviz_nbclust(scaled_df, k.max = 10, pam,method="gap_stat",nboot = 50)+
#labs(subtitle = "Gap statistic method")
labs(title = "",subtitle = "") + # for the figure in the report
xlab("Number of clusters") +
ggsave("Figures/pam-gap-statistic.png",width=2,height=3,units="in",device="png",dpi="retina")
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(hexbin)
library(RColorBrewer)
library(ggrepel)
library(ggfortify)
library(extrafont)
library(factoextra)
library("FactoMineR")
library(NbClust)
library(cluster)
library(clValid)
library(ggfortify)
A_df=read.csv("Data/Study_A.csv")
B_df=read.csv("Data/Study_B.csv")
C_df=read.csv("Data/Study_C.csv")
D_df=read.csv("Data/Study_D.csv")
E_df=read.csv("Data/Study_E.csv")
summary(A_df)
A_df = subset(A_df, VisitDay==0)
B_df = subset(B_df, VisitDay==0)
C_df = subset(C_df, VisitDay==0)
D_df = subset(D_df, VisitDay==0)
E_df = subset(E_df, VisitDay==0)
A_sub = A_df[ , -which(names(A_df) %in% c("Study","Country","PatientID","SiteID","RaterID",
"AssessmentiD","TxGroup","VisitDay","PANSS_Total","LeadStatus"))]
B_sub = B_df[ , -which(names(B_df) %in% c("Study","Country","PatientID","SiteID","RaterID",
"AssessmentiD","TxGroup","VisitDay","PANSS_Total","LeadStatus"))]
C_sub = C_df[ , -which(names(C_df) %in% c("Study","Country","PatientID","SiteID","RaterID",
"AssessmentiD","TxGroup","VisitDay","PANSS_Total","LeadStatus"))]
D_sub = D_df[ , -which(names(D_df) %in% c("Study","Country","PatientID","SiteID","RaterID",
"AssessmentiD","TxGroup","VisitDay","PANSS_Total","LeadStatus"))]
E_sub = E_df[ , -which(names(E_df) %in% c("Study","Country","PatientID","SiteID","RaterID",
"AssessmentiD","TxGroup","VisitDay","PANSS_Total","LeadStatus"))]
names(A_sub)
combined_df = rbind(A_sub,B_sub,C_sub,D_sub,E_sub)
A_scale = scale(A_sub)
B_scale = scale(B_sub)
C_scale = scale(C_sub)
D_scale = scale(D_sub)
E_scale = scale(E_sub)
scaled_df = scale(combined_df)
summary(scaled_df)
#cvalid.out = clValid(scaled_df, maxitems = 3000, nClust = 2:8, clMethods = c("kmeans","pam"), validation = c("internal", "stability"))
#summary(cvalid.out)
# Elbow method
fviz_nbclust(scaled_df, kmeans, method = "wss",print.summary=TRUE) +
geom_vline(xintercept = 2, linetype = 2)+
#labs(subtitle = "Elbow method") +
labs(title = "",subtitle = "") + # for the figure in the report
ggsave("Figures/k-means-elbow.png",width=2,height=3,units="in",device="png",dpi="retina")
# Silhouette method
fviz_nbclust(scaled_df, kmeans, method = "silhouette")+
#labs(subtitle = "Silhouette method")
labs(title = "",subtitle = "") + # for the figure in the report
ggsave("Figures/k-means-silhouette.png",width=2,height=3,units="in",device="png",dpi="retina")
# Gap statistic
# nboot = 50 to keep the function speedy. Number of Monte Carlo ("bootstrap") samples.
# recommended value: nboot= 500 for your analysis.
# Use verbose = FALSE to hide computing progression.
# set.seed(1)
gc()
fviz_nbclust(scaled_df, kmeans,k.max = 8,iter.max=30,nstart = 25,method="gap_stat",nboot = 50)+
#labs(subtitle = "Gap statistic method") +
labs(title = "",subtitle = "") + # for the figure in the report
xlab("Number of clusters") +
ggsave("Figures/k-means-gap-statistic.png",width=2,height=3,units="in",device="png",dpi="retina")
